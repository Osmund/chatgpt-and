# Duck-Vision + Anda: Arkitektur-beslutninger

## ‚úÖ Anbefalinger for implementasjon

### 1. Arkitektur: DuckVisionService i ServiceManager

**Anbefaling: A + C kombinert**

```python
# I service_manager.py - ny service:
class DuckVisionService(BaseService):
    """Service for MQTT kommunikasjon med Duck-Vision kamera"""
    
    def __init__(self, announce_callback, listen_callback, speak_callback):
        super().__init__()
        self.announce = announce_callback
        self.listen = listen_callback
        self.speak = speak_callback
        self.vision_handler = None
        self.waiting_for_name = False
    
    async def start(self):
        self.vision_handler = DuckVisionHandler(
            broker_host="localhost",
            on_face_detected=self._on_face_detected,
            on_unknown_face=self._on_unknown_face,
            on_object_detected=self._on_object_detected
        )
        if self.vision_handler.connect():
            logger.info("‚úì Duck-Vision service started")
        else:
            logger.warning("‚ö†Ô∏è Duck-Vision not available")
    
    async def stop(self):
        if self.vision_handler:
            self.vision_handler.disconnect()
```

**Fordeler:**
- ‚úÖ Konsistent med eksisterende arkitektur
- ‚úÖ Kan startes/stoppes uavhengig
- ‚úÖ Egen lifecycle management
- ‚úÖ Kan disable hvis kamera ikke tilgjengelig

---

### 2. Face Recognition: Announcement (ikke wake word)

**Anbefaling: C) Announcement-systemet**

```python
def _on_unknown_face(self):
    """Ukjent ansikt ‚Üí direkte announcement (som hunger/boredom)"""
    self.announce("Hei! Jeg ser deg, men jeg vet ikke hvem du er. Hvem er du?")
    self.waiting_for_name = True
    # STT h√•ndteres av main loop - service setter bare flag
```

**Fordeler:**
- ‚úÖ Naturlig interaksjon (ser deg ‚Üí sier noe med en gang)
- ‚úÖ Konsistent med hunger/boredom announcements
- ‚úÖ Ikke avhengig av wake word
- ‚úÖ Kan avbrytes hvis bruker sier "Samantha" for annen kommando

**Alternativ:** Hvis du vil v√¶re mindre "p√•trengende", kan f√∏rste gang v√¶re announcement, senere kjente personer bare logges stille.

---

### 3. "Hva ser du?": AI Tool (primary) + Fallback

**Anbefaling: B) AI Tool (med C som backup)**

```python
# I tools.py - nytt AI tool:
{
    "type": "function",
    "function": {
        "name": "look_around",
        "description": "Use the camera to see what objects or people are currently visible in the room. Returns a list of detected objects with Norwegian names.",
        "parameters": {
            "type": "object",
            "properties": {},
            "required": []
        }
    }
}

# Implementation:
def look_around() -> dict:
    """Request object detection from Duck-Vision"""
    service_manager.vision_service.request_object_detection()
    # Wait for response (med timeout 5s)
    result = service_manager.vision_service.get_last_detection(timeout=5.0)
    return {"objects": result}
```

**Fordeler:**
- ‚úÖ AI bestemmer n√•r den trenger √• "se"
- ‚úÖ Kan brukes i kontekst: "Er Magnus her?" ‚Üí AI kaller look_around() f√∏rst
- ‚úÖ Mer naturlig enn hardkodede kommandoer

**Fallback:** Behold ogs√• direkte kommando "hva ser du" som trigger samme funksjon.

---

### 4. Database: Hybrid (metadata i duck_memory.db)

**Anbefaling: C) Hybrid l√∏sning**

**Pi 5 (Duck-Vision):**
```
/home/admog/Code/Duck-Vision/data/known_faces/{name}/
‚îú‚îÄ‚îÄ encodings.pkl      # Face encoding vectors (128D numpy array)
‚îî‚îÄ‚îÄ metadata.json      # N√•r lagret, confidence threshold, etc
```

**Pi 4 (duck_memory.db):**
```sql
-- Ny tabell:
CREATE TABLE IF NOT EXISTS known_people (
    name TEXT PRIMARY KEY,
    first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    times_seen INTEGER DEFAULT 1,
    notes TEXT  -- "Bor i Oslo", "Magnus sin bror", etc
);

-- Oppdater existing profile_facts:
INSERT INTO profile_facts (fact_type, fact_value) 
VALUES ('known_person', 'Magnus');
```

**Workflow:**
1. Duck-Vision lagrer face encoding (Pi 5)
2. N√•r person gjenkjennes ‚Üí MQTT event
3. Anda logger i known_people + profile_facts (Pi 4)
4. Kan senere sp√∏rre: "Har du sett Magnus i dag?"

**Fordeler:**
- ‚úÖ Face encodings er for store for database (128D floats √ó mange bilder)
- ‚úÖ Metadata i database gir Anda "memory" om personer
- ‚úÖ Kan integrere med existing profile system
- ‚úÖ Separation of concerns

---

### 5. Testing: Pi 5 KLAR! ‚úÖ

**Status Duck-Vision (Pi 5):**
- ‚úÖ IMX500 SDK installert og testet
- ‚úÖ Object detection: 0.6ms latency, perfekt norske navn
- ‚úÖ Face detection: Fungerer med PoseNet
- ‚úÖ dlib + face_recognition: **FERDIG INSTALLERT** (exit code 0!)
- ‚úÖ MQTT client klar
- ‚úÖ All kode skrevet og klar

**Neste steg:**
1. **Test face recognition** (5 min):
   ```bash
   # P√• Pi 5
   cd /home/admog/Code/Duck-Vision
   python3 -c "import face_recognition; print('‚úì face_recognition works!')"
   python3 demo_face_recognition.py  # Lag denne testen
   ```

2. **Start Duck-Vision system** (1 min):
   ```bash
   python3 duck_vision.py
   ```

3. **Implementer p√• Pi 4** (30-60 min):
   - Installer MQTT broker
   - Kopier duck_vision_integration.py
   - Lag DuckVisionService
   - Legg til AI tool
   - Test!

---

### 6. Scope: Pilot f√∏rst (object detection), deretter full

**Anbefaling: B ‚Üí A) Object detection f√∏rst, s√• face recognition**

**FASE 1 (pilot, 30 min implementasjon):**
```python
‚úì Object detection only
‚úì AI tool: look_around()
‚úì Kommando: "Hva ser du?"
‚úì DuckVisionService (basic)
‚úì MQTT kommunikasjon
```

**Fordeler:**
- ‚úÖ Raskeste veien til working demo
- ‚úÖ Ingen privacy concerns (ingen ansiktsdata)
- ‚úÖ Tester full MQTT stack
- ‚úÖ Kan vise resultat med √©n gang (0.6ms deteksjon!)
- ‚úÖ Mindre kompleks workflow

**FASE 2 (full, +30 min):**
```python
‚úì Face recognition
‚úì Unknown face announcements
‚úì Learning workflow med samtykke
‚úì Database integration (known_people)
‚úì Greetings ved kjent ansikt
```

**Hvorfor ikke face f√∏rst?**
- ‚ö†Ô∏è Mer kompleks (announcements, STT workflow, database)
- ‚ö†Ô∏è Krever testing med reelle personer
- ‚ö†Ô∏è Privacy considerations (GDPR, samtykke)
- ‚ö†Ô∏è Flere edge cases (hva hvis name extraction feiler?)

**Konkret plan:**

**PILOT (i dag):**
1. Lag minimal DuckVisionService (kun object detection)
2. Lag look_around() AI tool
3. Test: "Samantha, hva ser du?" ‚Üí "Jeg ser en laptop"
4. ‚úÖ SUCCESS! System fungerer!

**FULL (n√•r pilot virker):**
5. Utvid DuckVisionService med face callbacks
6. Legg til announcement system
7. Legg til database tabell
8. Test full face learning workflow
9. ‚úÖ COMPLETE! Full vision system!

---

**FASE 2+ (framtidig utvidelser):**
- [ ] "Jeg har ikke sett Magnus p√• 3 dager" (query known_people)
- [ ] Memory integration: "Sist jeg s√• deg hadde du briller"
- [ ] Confidence-based greetings: h√∏y confidence ‚Üí "Hei Magnus!", lav ‚Üí "Er du Magnus?"
- [ ] Multi-face detection: "Jeg ser b√•de Magnus og Maria"
- [ ] Object memory: "Du spurte om laptop for 10 min siden, den er fortsatt der"
- [ ] Spatial memory: "Laptopen er p√• bordet til venstre"
- [ ] Change detection: "Noen har flyttet koppen"

---

## üìÅ Filer du trenger √• endre (Pi 4):

### FASE 1 (Pilot - Object Detection):

1. **duck_vision_integration.py** (kopier fra Pi 5)
   - `scp duck_vision_integration.py admog@oDuckberry-2.local:~/chatgpt-and/`

2. **service_manager.py**
   - Legg til `DuckVisionService` class (minimal version)
   - Import `DuckVisionHandler`

3. **main.py**
   - Initialize vision service: `vision_service = DuckVisionService(...)`
   - Start service i service_manager

4. **tools.py** (eller der du har AI tools)
   - Legg til `look_around()` function
   - Legg til i tools array for OpenAI

### FASE 2 (Full - Face Recognition):

5. **service_manager.py** (utvid)
   - Legg til face detection callbacks
   - Legg til announcement system

6. **duck_memory.db** (SQL migration)
   - Kj√∏r CREATE TABLE for `known_people`

7. **main.py** (utvid)
   - Legg til database logging for face events

---

## üöÄ Installasjon Pi 4 (5 minutter):

```bash
ssh admog@oDuckberry-2.local

# 1. MQTT Broker
sudo apt-get update
sudo apt-get install -y mosquitto mosquitto-clients
sudo systemctl enable mosquitto
sudo systemctl start mosquitto

# 2. Python dependencies
cd ~/chatgpt-and
pip3 install paho-mqtt

# 3. Test MQTT
mosquitto_sub -t "duck/#" -v &
# La st√• √•pen i bakgrunnen for testing

# 4. Database migration
sqlite3 duck_memory.db << EOF
CREATE TABLE IF NOT EXISTS known_people (
    name TEXT PRIMARY KEY,
    first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_seen TIMESTAMPintegrasjon:

### FASE 1 (Pilot - Object Detection):

| Oppgave | Tid | Status |
|---------|-----|--------|
| Installer MQTT broker (Pi 4) | 5 min | M√• gj√∏res |
| Kopier integrasjonsfil | 1 min | M√• gj√∏res |
| Lag minimal DuckVisionService | 10 min | M√• kodes |
| Legg til AI tool: look_around() | 10 min | M√• kodes |
| Testing + debugging | 10 min | M√• gj√∏res |
| **PILOT TOTALT** | **~35 min** | ‚úÖ **Test system!** |

### FASE 2 (Full - Face Recognition):

| Oppgave | Tid | Status |
|---------|-----|--------|
| Utvid DuckVisionService (callbacks) | 15 min | M√• kodes |
| Legg til announcement system | 5 min | M√• kodes |
| Database migration (known_people) | 2 min | M√• kj√∏res |
| Testing face learning workflow | 20 min | M√• gj√∏res |
| **FULL TOTALT** | **+40 min** | |

### **TOTAL TID: ~1 time 15 min** (men 35 min til working demo!)tegrasjon:

| Oppgave | Tid | Status |
|---------|-----|--------|
| Test face recognition (Pi 5) | 5 min | Klar n√• |
| Installer MQTT broker (Pi 4) | 5 min | M√• gj√∏res |
| Kopier integrasjonsfil | 1 min | M√• gj√∏res |
| Lag DuckVisionService | 15 min | M√• kodes |
| Legg til AI tool | 10 min | M√• kodes |
| Database migration | 2 min | M√• kj√∏res |
| Testing + debugging | 30 min | M√• gj√∏res |
| **TOTALT** | **~1 time** | |

---

## ‚úÖ Oppsummering

**Implementasjonsplan:**
1. ‚úÖ Test face recognition p√• Pi 5 **F√òRST** (sikre at alt fungerer)
2. Installer MQTT broker p√• Pi 4
3. Lag DuckVisionService i service_manager.py
4. Lag AI tool look_around() i tools.py
5. Kj√∏r database migration
6. Start begge systemer og test!

**Arkitektur-valg:**
- Service-based (ikke direkte i main.py)
- Announcement for ansiktsgjenkjenning (ikke wake word)
- AI tool for "se rundt deg" (AI bestemmer)
- Hybrid database (encodings p√• Pi 5, metadata p√• Pi 4)

**Status:** 
- Pi 5: ‚úÖ KLAR
- Pi 4: üî® Trenger 1 time implementasjon

---

**Neste steg: Test face_recognition p√• Pi 5, s√• er vi klare til full integrasjon! ü¶Ü‚ö°**
