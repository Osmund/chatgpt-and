# Duck-Vision + Anda Integrasjon: Setup Guide

## ğŸ¯ Oversikt

Dette dokumentet beskriver **nÃ¸yaktig** hvordan du integrerer Duck-Vision (Pi 5) med Anda/Samantha (Pi 4).

**Alle steg er copy-paste klare!** Ingen gjetning, bare fÃ¸lg instruksjonene.

### Hva oppnÃ¥r vi?

1. **Ansiktsgjenkjenning med samtykke-workflow:**
   - Ukjent person â†’ Anda spÃ¸r "Hvem er du?"
   - FÃ¥r navn â†’ "FÃ¥r jeg lov Ã¥ huske deg?"
   - Hvis ja â†’ Lagrer ansikt med navn
   - Neste gang â†’ "Hei [navn]!" direkte!

2. **Object detection pÃ¥ kommando:**
   - "Hva ser du?" â†’ Anda forteller hva Duck-Vision ser
   - 0.6ms latency fra IMX500 AI-chip!

3. **MQTT kommunikasjon:**
   - Real-time events mellom Pi 5 og Pi 4
   - KjÃ¸rer i bakgrunnen, stÃ¸rer ikke existing funksjonalitet

## ğŸ“‹ Arkitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          MQTT           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pi 5 (Vision)     â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚   Pi 4 (Anda)       â”‚
â”‚  oDuckberry-vision  â”‚                          â”‚  oDuckberry-2       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ IMX500 AI Camera  â”‚                          â”‚ â€¢ MQTT Broker       â”‚
â”‚ â€¢ Object Detection  â”‚  Events: face, object    â”‚ â€¢ chatgpt_voice.py  â”‚
â”‚ â€¢ Face Recognition  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚ â€¢ TTS/STT           â”‚
â”‚ â€¢ 0.6ms latency âš¡   â”‚                          â”‚ â€¢ OpenAI API        â”‚
â”‚                     â”‚  Commands: learn, detect â”‚                     â”‚
â”‚                     â”‚  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Setup: Pi 4 (Anda/Samantha)

### 1. Installer MQTT Broker

```bash
# SSH til Pi 4
ssh admog@oDuckberry-2.local

# Installer mosquitto
sudo apt-get update
sudo apt-get install -y mosquitto mosquitto-clients

# Enable og start service
sudo systemctl enable mosquitto
sudo systemctl start mosquitto

# Verifiser at det kjÃ¸rer
sudo systemctl status mosquitto

# Test med subscriber (i ett terminal vindu)
mosquitto_sub -t "duck/#" -v
```

### 2. Kopier integrasjonsfil

```bash
# PÃ¥ Pi 5, kopier til Pi 4:
scp /home/admog/Code/Duck-Vision/duck_vision_integration.py admog@oDuckberry-2.local:~/chatgpt-and/
```

### 3. Installer Python dependencies pÃ¥ Pi 4

```bash
# PÃ¥ Pi 4
cd ~/chatgpt-and
pip3 install paho-mqtt
```

### 4. Integrer i chatgpt_voice.py

**VIKTIG:** Dette er KOMPLETT kode klar for copy-paste!

#### Steg 4.1: Legg til imports i toppen av filen

```python
# Finn linjen med dine andre imports, legg til disse:
from duck_vision_integration import DuckVisionHandler
import re
```

#### Steg 4.2: Legg til hjelpefunksjoner (fÃ¸r main())

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DUCK-VISION HELPER FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_name_from_text(text):
    """
    Ekstraher navn fra bruker-respons.
    Eksempel: "jeg heter Magnus" â†’ "Magnus"
    """
    text = text.lower()
    
    # Patterns for navn
    patterns = [
        r"jeg heter (\w+)",
        r"jeg er (\w+)", 
        r"mitt navn er (\w+)",
        r"navnet mitt er (\w+)",
        r"kaller meg (\w+)",
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            name = match.group(1)
            return name.capitalize()
    
    # Hvis ingen pattern matcher, bruk fÃ¸rste ord >3 bokstaver
    words = text.split()
    for word in words:
        word = word.strip('.,!?')
        if len(word) > 3 and word.isalpha():
            return word.capitalize()
    
    return None

def is_affirmative(text):
    """Sjekk om respons er bekreftende"""
    text = text.lower()
    yes_words = ['ja', 'yes', 'ok', 'greit', 'gjerne', 'sure', 'yep', 'jepp', 'sikkert']
    return any(word in text for word in yes_words)
```

#### Steg 4.3: Legg til Duck-Vision setup i main()

**FINN denne linjen i din main():**
```python
def main():
    # Her er ditt existing setup...
```

**LEGG TIL rett etter andre initialiseringer (fÃ¸r while-lÃ¸kken):**

```python
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DUCK-VISION INTEGRATION SETUP
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # Global variabel for Ã¥ holde styr pÃ¥ pending person
    pending_person_name = [None]  # List for closure
    
    def on_face_detected(name, confidence):
        """Callback nÃ¥r kjent ansikt detekteres"""
        import datetime
        hour = datetime.datetime.now().hour
        
        if hour < 10:
            greeting = "God morgen"
        elif hour < 18:
            greeting = "Hei"
        else:
            greeting = "God kveld"
        
        speak(f"{greeting} {name}!")
        print(f"ğŸ‘‹ Hilste pÃ¥ {name} (confidence: {confidence:.2%})")
    
    def on_unknown_face():
        """Callback nÃ¥r ukjent ansikt detekteres"""
        speak("Hei! Jeg ser deg, men jeg vet ikke hvem du er. Hvem er du?")
        
        # Lytt etter navn
        response = listen()  # Bruk din existing listen() funksjon
        if response:
            name = extract_name_from_text(response)
            if name:
                # SpÃ¸r om lov til Ã¥ huske
                speak(f"Hei {name}! FÃ¥r jeg lov Ã¥ huske deg?")
                confirm = listen()
                
                if confirm and is_affirmative(confirm):
                    # Send kommando til Duck-Vision
                    vision.learn_person(name)
                    pending_person_name[0] = name
                    
                    speak("Supert! Se mot kameraet pÃ¥ veggen...")
                    time.sleep(3)  # Gi tid til Ã¥ ta bilde
                    speak(f"Takk {name}! NÃ¥ kjenner jeg deg!")
                    
                    pending_person_name[0] = None
                else:
                    speak("Ok, jeg husker deg ikke da.")
            else:
                speak("Beklager, jeg hÃ¸rte ikke navnet ditt.")
    
    def on_object_detected(obj_name, confidence):
        """Callback nÃ¥r objekt detekteres"""
        speak(f"Jeg ser en {obj_name}")
        print(f"ğŸ‘ï¸ Detektert: {obj_name} (confidence: {confidence:.2%})")
    
    # Initialize Duck-Vision handler
    print("\nğŸ¦† Connecting to Duck-Vision...")
    vision = DuckVisionHandler(
        broker_host="localhost",  # MQTT broker pÃ¥ samme maskin
        on_face_detected=on_face_detected,
        on_unknown_face=on_unknown_face,
        on_object_detected=on_object_detected
    )
    
    if vision.connect():
        print("âœ“ Duck-Vision integrasjon aktiv!")
    else:
        print("âš ï¸ Duck-Vision ikke tilgjengelig (kjÃ¸rer den pÃ¥ Pi 5?)")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # END DUCK-VISION SETUP
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Steg 4.4: Legg til kommandohÃ¥ndtering i din conversation loop

**FINN der du hÃ¥ndterer bruker-input (vanligvis inne i while-lÃ¸kken):**

```python
# Der du har noe som:
# user_input = listen()
# if "vÃ¦r" in user_input:
#     # handle weather
```

**LEGG TIL disse Duck-Vision kommandoene:**

```python
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # DUCK-VISION COMMANDS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    # "Hva ser du?" - Object detection
    if any(phrase in user_input.lower() for phrase in ["hva ser du", "hva kan du se", "se etter"]):
        speak("La meg se...")
        vision.request_object_detection()
        continue  # GÃ¥ til neste loop iteration
    
    # "Hvem kjenner du?" - List known people
    if any(phrase in user_input.lower() for phrase in ["hvem kjenner du", "hvem kan du", "kjenner du noen"]):
        speak("La meg tenke...")
        vision.list_known_people()
        # Du kan ogsÃ¥ legge til en callback i DuckVisionHandler for Ã¥ fÃ¥ listen tilbake
        continue
    
    # "Glem [navn]" - Forget person
    if "glem" in user_input.lower():
        name_to_forget = extract_name_from_text(user_input)
        if name_to_forget:
            vision.forget_person(name_to_forget)
            speak(f"Ok, jeg har glemt {name_to_forget}")
        else:
            speak("Hvem skal jeg glemme?")
        continue
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ... resten av dine existing commands ...
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Steg 4.5: Cleanup ved exit

**FINN der du cleaner up (vanligvis nederst i main() eller i finally block):**

```python
    # Legg til fÃ¸r exit:
    print("\nğŸ›‘ Kobler fra Duck-Vision...")
    vision.disconnect()
```

## ğŸš€ Setup: Pi 5 (Duck-Vision)

Alt er allerede konfigurert! Bare start systemet:

```bash
# SSH til Pi 5
ssh admog@oDuckberry-vision.local

cd ~/Code/Duck-Vision

# Start Duck-Vision
python3 duck_vision.py
```

## ğŸ§ª Testing

### Test 1: MQTT Kommunikasjon

**Terminal 1 (Pi 4):**
```bash
mosquitto_sub -t "duck/#" -v
```

**Terminal 2 (Pi 5):**
```bash
cd ~/Code/Duck-Vision
python3 -c "
import paho.mqtt.client as mqtt
import json
client = mqtt.Client()
client.connect('oDuckberry-2.local', 1883)
client.publish('duck/vision/face', json.dumps({'person_name': 'Test', 'is_known': True}))
print('âœ“ Sent test message')
"
```

Du skal se meldingen i Terminal 1!

### Test 2: Full Workflow - Ukjent Person

1. Start Anda pÃ¥ Pi 4: `python3 chatgpt_voice.py`
2. Start Duck-Vision pÃ¥ Pi 5: `python3 duck_vision.py`
3. GÃ¥ foran kamera pÃ¥ Pi 5
4. **Forventet:**
   - Anda: "Hei! Hvem er du?"
   - Du: "Jeg heter Magnus"
   - Anda: "Hei Magnus! FÃ¥r jeg lov Ã¥ huske deg?"
   - Du: "Ja"
   - Anda: "Supert! Se mot kameraet..."
   - [2 sekunder pause]
   - Anda: "Takk! NÃ¥ kjenner jeg deg, Magnus!"

### Test 3: Full Workflow - Kjent Person

1. GÃ¥ foran kamera igjen
2. **Forventet:**
   - Anda: "Hei Magnus!" (med en gang!)

### Test 4: Object Detection

1. Si til Anda: "Hva ser du foran deg?"
2. **Forventet:**
   - Anda: "La meg se..."
   - [Duck-Vision detekterer objekt pÃ¥ 0.6ms!]
   - Anda: "Jeg ser en laptop" (eller hva enn som er der)

## ğŸ“Š MQTT Topics

### Events fra Duck-Vision â†’ Anda

| Topic | Payload | Beskrivelse |
|-------|---------|-------------|
| `duck/vision/face` | `{"person_name": "Magnus", "is_known": true, "confidence": 0.87}` | Ansikt detektert |
| `duck/vision/object` | `{"object_name": "kopp", "confidence": 0.92}` | Objekt detektert |
| `duck/vision/event` | `{"type": "person_learned", "name": "Magnus", "success": true}` | Generisk event |

### Commands fra Anda â†’ Duck-Vision

| Topic | Payload | Beskrivelse |
|-------|---------|-------------|
| `duck/samantha/commands` | `{"command": "detect_object"}` | Be om object detection |
| `duck/samantha/commands` | `{"command": "learn_person", "name": "Magnus"}` | LÃ¦r ny person |
| `duck/samantha/commands` | `{"command": "forget_person", "name": "Magnus"}` | Glem person |
| `duck/samantha/commands` | `{"command": "list_people"}` | List kjente personer |

## ğŸ¯ Eksempel: Komplett Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCENARIO: Ukjent person kommer inn i rommet               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. [Pi 5] IMX500 detekterer ansikt â†’ "ukjent" (10ms)
   â”œâ”€ duck_vision.py: face_recognizer.detect_faces()
   â””â”€ Sender MQTT: duck/vision/face
      {"person_name": "ukjent", "is_known": false}

2. [Pi 4] Anda mottar event via MQTT callback
   â”œâ”€ on_unknown_face() kalles
   â””â”€ TTS: "Hei! Jeg ser deg, men jeg vet ikke hvem du er. Hvem er du?"

3. [Person] "Jeg heter Magnus"
   â”œâ”€ STT pÃ¥ Pi 4: tekst = "jeg heter magnus"
   â””â”€ extract_name(): "Magnus"

4. [Pi 4] Anda spÃ¸r om samtykke
   â””â”€ TTS: "Hei Magnus! FÃ¥r jeg lov Ã¥ huske deg?"

5. [Person] "Ja"
   â”œâ”€ STT: "ja"
   â””â”€ Sender MQTT: duck/samantha/commands
      {"command": "learn_person", "name": "Magnus"}

6. [Pi 5] Duck-Vision mottar kommando
   â”œâ”€ Tar bilde med IMX500
   â”œâ”€ face_recognizer.add_person("Magnus", image)
   â”œâ”€ Lagrer encoding til disk
   â””â”€ Sender MQTT: duck/vision/event
      {"type": "person_learned", "name": "Magnus", "success": true}

7. [Pi 4] Anda bekrefter
   â””â”€ TTS: "Takk! NÃ¥ kjenner jeg deg, Magnus!"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCENARIO: Magnus kommer tilbake senere                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. [Pi 5] IMX500 detekterer ansikt â†’ "Magnus" (15ms!)
   â””â”€ Sender MQTT: duck/vision/face
      {"person_name": "Magnus", "is_known": true, "confidence": 0.87}

2. [Pi 4] Anda hilser direkte
   â””â”€ TTS: "Hei Magnus!" ğŸ‘‹
```

## ğŸ› Troubleshooting

### Problem: "Connection refused" pÃ¥ MQTT

**LÃ¸sning:**
```bash
# PÃ¥ Pi 4
sudo systemctl status mosquitto
sudo systemctl restart mosquitto

# Sjekk at den lytter:
sudo netstat -tulpn | grep 1883
```

### Problem: Duck-Vision fÃ¥r ikke kontakt med broker

**LÃ¸sning:**
```bash
# PÃ¥ Pi 5, test MQTT connection:
mosquitto_pub -h oDuckberry-2.local -t "test" -m "hello"

# Hvis det feiler, sjekk .env fil:
cat /home/admog/Code/Duck-Vision/.env
# Skal inneholde: MQTT_BROKER=oDuckberry-2.local
```

### Problem: Callbacks kalles ikke

**Debug:**
```python
# I duck_vision_integration.py, legg til debug logging:
def _on_message(self, client, userdata, msg):
    print(f"DEBUG: Received {msg.topic}: {msg.payload}")
    # ... rest of code
```

### Problem: Face recognition er treg

**Forventet:**
- FÃ¸rste deteksjon: ~4000ms (laster firmware)
- PÃ¥fÃ¸lgende: ~10-30ms

Hvis tregere, sjekk:
```bash
# PÃ¥ Pi 5
htop  # Sjekk CPU/RAM bruk
```

## âœ… Sjekkliste fÃ¸r produksjon

- [ ] MQTT broker kjÃ¸rer pÃ¥ Pi 4
- [ ] Duck-Vision starter uten feil pÃ¥ Pi 5
- [ ] MQTT kommunikasjon fungerer begge veier
- [ ] Face detection fungerer (test med ukjent person)
- [ ] Face learning fungerer (test full workflow)
- [ ] Face recognition fungerer (test kjent person)
- [ ] Object detection fungerer ("hva ser du?")
- [ ] Anda integrering komplett i chatgpt_voice.py
- [ ] Systemd services satt opp (optional)

## ğŸš€ Autostart (Optional)

Lag systemd service for autostart:

**PÃ¥ Pi 5** - `/etc/systemd/system/duck-vision.service`:
```ini
[Unit]
Description=Duck-Vision AI Camera System
After=network.target

[Service]
Type=simple
User=admog
WorkingDirectory=/home/admog/Code/Duck-Vision
ExecStart=/usr/bin/python3 /home/admog/Code/Duck-Vision/duck_vision.py
Restart=always

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl enable duck-vision
sudo systemctl start duck-vision
```

---

**Status: Klar til testing nÃ¥r face_recognition er ferdig installert! ğŸ¦†âš¡**
