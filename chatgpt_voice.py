from pydub import AudioSegment
from scipy.signal import resample
import sounddevice as sd
import time
import random
import threading
from duck_beak import Beak, CLOSE_DEG, OPEN_DEG, TRIM_DEG, JITTER, BEAT_MS_MIN, BEAT_MS_MAX, SERVO_CHANNEL
import requests                                                                                                                                                                                           
import os
from dotenv import load_dotenv
import azure.cognitiveservices.speech as speechsdk
import numpy as np
from rgb_duck import set_blue, set_red, set_green, off, blink_yellow, stop_blink, blink_yellow_purple, set_intensity
import pvporcupine
import json
import sys
import signal
import atexit
import struct
import traceback
from datetime import datetime, timedelta
from duck_memory import MemoryManager
from duck_user_manager import UserManager
import uuid

# Flush stdout umiddelbart slik at print vises i journalctl
sys.stdout.reconfigure(line_buffering=True)

# MAX98357A SD pin skal kobles til fast 3.3V (pin 1 eller 17)
# Dette holder forsterkeren alltid p√• for rask respons
print("MAX98357A SD pin skal v√¶re koblet til 3.3V - forsterker alltid p√•", flush=True)

# Fil for eksterne meldinger
MESSAGE_FILE = "/tmp/duck_message.txt"
# Fil for AI-modell konfigurering
MODEL_CONFIG_FILE = "/tmp/duck_model.txt"
DEFAULT_MODEL = "gpt-3.5-turbo"
# Fil for personlighet
PERSONALITY_FILE = "/tmp/duck_personality.txt"
# Fil for TTS-stemme
VOICE_FILE = "/tmp/duck_voice.txt"
DEFAULT_VOICE = "nb-NO-IselinNeural"
# Fil for nebbet-kontroll
BEAK_FILE = "/tmp/duck_beak.txt"
# Fil for talehastighet (0-100, 50 = normal)
SPEED_FILE = "/tmp/duck_speed.txt"
# Fil for volum (0-100, 50 = normal)
VOLUME_FILE = "/tmp/duck_volume.txt"
# Filer for AI-query fra kontrollpanel
AI_QUERY_FILE = "/tmp/duck_ai_query.txt"
AI_RESPONSE_FILE = "/tmp/duck_ai_response.txt"
# Konfigurasjonsfiler
MESSAGES_FILE = "/home/admog/Code/chatgpt-and/messages.json"
# Filer for sang-foresp√∏rsler
SONG_REQUEST_FILE = "/tmp/duck_song_request.txt"
SONG_STOP_FILE = "/tmp/duck_song_stop.txt"

# Fade in/out lengde i millisekunder (for √• redusere knepp ved start/slutt)
# Sett til 0 for √• deaktivere fade
FADE_MS = 150  # 150ms fade in/out

# Nebb-synkronisering (juster for bedre timing)
BEAK_CHUNK_MS = 30  # Hvor ofte nebbet oppdateres (mindre = mer responsivt)
BEAK_PRE_START_MS = 0  # Start nebb f√∏r aplay (negativ = etter aplay starter)
# Sett BEAK_PRE_START_MS = -150 hvis nebb starter for tidlig

# Finn USB mikrofon dynamisk (unng√• hardkodede device-numre som endrer seg ved reboot)
def find_usb_microphone():
    """Finn sounddevice index for USB PnP Sound Device"""
    devices = sd.query_devices()
    for i, device in enumerate(devices):
        if 'USB PnP Sound Device' in device['name'] and device['max_input_channels'] > 0:
            print(f"Fant USB mikrofon: device {i} ({device['name']})", flush=True)
            return i
    # Fallback til default
    print("Fant ikke USB mikrofon, bruker default", flush=True)
    return None

def find_hifiberry_output():
    """Finn sounddevice index for Google Voice HAT / MAX98357A"""
    devices = sd.query_devices()
    for i, device in enumerate(devices):
        # S√∏k etter Google Voice HAT eller voicehat i navnet
        if ('googlevoicehat' in device['name'].lower() or 
            'voicehat' in device['name'].lower() or
            'hifiberry' in device['name'].lower()) and device['max_output_channels'] > 0:
            print(f"Fant I2S DAC: device {i} ({device['name']})", flush=True)
            return i
    # Fallback til default
    print("Fant ikke I2S DAC, bruker default", flush=True)
    return None

def find_usb_mic_alsa_card():
    """Finn ALSA card nummer for USB PnP Sound Device"""
    import re
    try:
        with open('/proc/asound/cards', 'r') as f:
            content = f.read()
            # S√∏k etter "USB PnP Sound Device" og finn card-nummeret
            match = re.search(r'^\s*(\d+)\s+\[.*?\]:\s+USB-Audio.*?USB PnP Sound Device', content, re.MULTILINE | re.IGNORECASE)
            if match:
                card_num = match.group(1)
                print(f"Fant USB mikrofon ALSA card: {card_num}", flush=True)
                return f"plughw:{card_num},0"
    except Exception as e:
        print(f"Kunne ikke lese /proc/asound/cards: {e}", flush=True)
    return "plughw:1,0"  # Fallback

# Cleanup-funksjon som sl√•r av alle LED ved avslutning
def cleanup():
    print("Sl√•r av LED og rydder opp...", flush=True)
    stop_blink()
    off()

# Registrer cleanup ved normal exit og ved signaler
atexit.register(cleanup)
signal.signal(signal.SIGTERM, lambda sig, frame: (cleanup(), sys.exit(0)))
signal.signal(signal.SIGINT, lambda sig, frame: (cleanup(), sys.exit(0)))

def wait_for_wake_word():
    set_blue()
    
    # Last inn Picovoice API-n√∏kkel fra .env
    load_dotenv()
    access_key = os.getenv('PICOVOICE_API_KEY')
    if not access_key:
        print("‚ö†Ô∏è  PICOVOICE_API_KEY mangler i .env - Porcupine kan ikke starte!", flush=True)
        print("Legg til: PICOVOICE_API_KEY=din_api_n√∏kkel i .env", flush=True)
        time.sleep(5)
        return None
    
    # Porcupine modell sti
    keyword_path = "porcupine/samantha_en_raspberry-pi_v4_0_0.ppn"
    if not os.path.exists(keyword_path):
        print(f"‚ö†Ô∏è  Porcupine modell ikke funnet: {keyword_path}", flush=True)
        time.sleep(5)
        return None
    
    print("Si 'Samantha' for √• vekke anda!", flush=True)
    
    # Finn USB mikrofon dynamisk
    usb_mic_device = find_usb_microphone()
    
    # Initialiser Porcupine
    porcupine = None
    audio_stream = None
    
    try:
        porcupine = pvporcupine.create(
            access_key=access_key,
            keyword_paths=[keyword_path],
            sensitivities=[0.5]  # 0.0 til 1.0, h√∏yere = mer sensitiv (flere false positives)
        )
        
        print(f"Porcupine startet! Sample rate: {porcupine.sample_rate} Hz, Frame length: {porcupine.frame_length}", flush=True)
        
        # USB mikrofon st√∏tter 48000 Hz, men Porcupine trenger 16000 Hz
        # Vi m√• resample
        mic_sample_rate = 48000
        porcupine_sample_rate = porcupine.sample_rate  # 16000 Hz
        ratio = mic_sample_rate / porcupine_sample_rate  # 3.0
        mic_frame_length = int(porcupine.frame_length * ratio)  # 512 * 3 = 1536
        
        # √òk buffer st√∏rrelse for √• unng√• overflows under resampling
        # Bruk 4x st√∏rre buffer for √• gi nok tid til prosessering
        mic_buffer_size = mic_frame_length * 4  # 1536 * 4 = 6144
        
        print(f"Resampling: {mic_sample_rate} Hz -> {porcupine_sample_rate} Hz (ratio: {ratio}), buffer: {mic_buffer_size}", flush=True)
        
        # Pr√∏v √• √•pne mikrofon-input i en retry-loop
        while True:
            try:
                audio_stream = sd.RawInputStream(
                    samplerate=mic_sample_rate,
                    blocksize=mic_buffer_size,
                    dtype='int16',
                    channels=1,
                    device=usb_mic_device
                )
                audio_stream.start()
                
                while True:
                    # Sjekk om det finnes en ekstern melding
                    if os.path.exists(MESSAGE_FILE):
                        try:
                            with open(MESSAGE_FILE, 'r', encoding='utf-8') as f:
                                message = f.read().strip()
                            os.remove(MESSAGE_FILE)
                            if message:
                                print(f"Ekstern melding mottatt: {message}", flush=True)
                                if message == '__START_CONVERSATION__':
                                    return '__START_CONVERSATION__'
                                else:
                                    return message
                        except Exception as e:
                            print(f"Feil ved lesing av meldingsfil: {e}", flush=True)
                    
                    # Sjekk om det finnes en sang-foresp√∏rsel
                    if os.path.exists(SONG_REQUEST_FILE):
                        try:
                            with open(SONG_REQUEST_FILE, 'r', encoding='utf-8') as f:
                                song_path = f.read().strip()
                            os.remove(SONG_REQUEST_FILE)
                            if song_path:
                                print(f"Sang-foresp√∏rsel mottatt: {song_path}", flush=True)
                                return f'__PLAY_SONG__{song_path}'  # Spesiell trigger for sang
                        except Exception as e:
                            print(f"Feil ved lesing av sang-foresp√∏rsel: {e}", flush=True)
                    
                    # Les audio fra mikrofon (st√∏rre buffer)
                    pcm_48k, overflowed = audio_stream.read(mic_buffer_size)
                    # Ignorer overflow warnings - forventet ved resampling
                    
                    # Konverter til numpy array
                    pcm_48k_array = np.frombuffer(pcm_48k, dtype=np.int16)
                    
                    # Prosesser flere frames (buffer inneholder flere porcupine frames)
                    # Split bufferen i chunks p√• mic_frame_length
                    for i in range(0, len(pcm_48k_array), mic_frame_length):
                        chunk = pcm_48k_array[i:i+mic_frame_length]
                        if len(chunk) < mic_frame_length:
                            break  # Siste chunk er for liten, skip
                        
                        # Resample til 16000 Hz
                        pcm_16k_array = resample(chunk, porcupine.frame_length)
                        pcm_16k = pcm_16k_array.astype(np.int16)
                        
                        # Sjekk for wake word
                        keyword_index = porcupine.process(pcm_16k)
                        if keyword_index >= 0:
                            print("Wake word 'Samantha' oppdaget!", flush=True)
                            return None  # Wake word oppdaget
                        
            except Exception as e:
                print(f"Input-enhet ikke klar enn√• (pr√∏ver igjen om 2s): {e}", flush=True)
                time.sleep(2)
                continue
                
    finally:
        # Cleanup
        if audio_stream is not None:
            audio_stream.stop()
            audio_stream.close()
        if porcupine is not None:
            porcupine.delete()

def clean_markdown_for_tts(text):
    """
    Fjerner Markdown-formatering fra tekst f√∏r TTS.
    Dette forhindrer at TTS sier 'asterisk asterisk' osv.
    """
    import re
    
    # Fjern bold/italic: **tekst** eller *tekst*
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)  # **bold**
    text = re.sub(r'\*(.+?)\*', r'\1', text)      # *italic*
    
    # Fjern underline: __tekst__ eller _tekst_
    text = re.sub(r'__(.+?)__', r'\1', text)      # __underline__
    text = re.sub(r'_(.+?)_', r'\1', text)        # _underline_
    
    # Fjern kodeblokker: ```kode``` eller `kode`
    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)  # ```code block```
    text = re.sub(r'`(.+?)`', r'\1', text)                   # `inline code`
    
    # Fjern lenker: [tekst](url) ‚Üí tekst
    text = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', text)
    
    # Fjern overskrifter: ### Overskrift ‚Üí Overskrift
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
    
    # Fjern liste-mark√∏rer: - item eller * item eller 1. item
    text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    
    return text

def speak(text, speech_config, beak):
    stop_blink()  # Stopp eventuell blinking
    set_red()  # LED r√∏d F√òR anda begynner √• snakke
    import tempfile
    import wave
    
    # Fjern Markdown-formatering f√∏r TTS
    text = clean_markdown_for_tts(text)
    
    # Les valgt stemme fra konfigurasjonsfil
    voice_name = DEFAULT_VOICE
    try:
        if os.path.exists(VOICE_FILE):
            with open(VOICE_FILE, 'r') as f:
                voice = f.read().strip()
                if voice:
                    voice_name = voice
    except Exception as e:
        print(f"Feil ved lesing av stemme-konfigurasjon: {e}, bruker default", flush=True)
    
    # Les nebbet-status
    beak_enabled = True
    try:
        if os.path.exists(BEAK_FILE):
            with open(BEAK_FILE, 'r') as f:
                beak_status = f.read().strip()
                beak_enabled = (beak_status != 'off')
    except Exception as e:
        print(f"Feil ved lesing av nebbet-konfigurasjon: {e}, nebbet aktivert", flush=True)
    
    # Les talehastighet (0-100, hvor 50 = normal)
    speed_value = 50
    try:
        if os.path.exists(SPEED_FILE):
            with open(SPEED_FILE, 'r') as f:
                speed_str = f.read().strip()
                if speed_str:
                    speed_value = int(speed_str)
    except Exception as e:
        print(f"Feil ved lesing av hastighet-konfigurasjon: {e}, bruker normal hastighet", flush=True)
    
    # Les volum (0-100, hvor 50 = normal)
    volume_value = 50
    try:
        if os.path.exists(VOLUME_FILE):
            with open(VOLUME_FILE, 'r') as f:
                volume_str = f.read().strip()
                if volume_str:
                    volume_value = int(volume_str)
    except Exception as e:
        print(f"Feil ved lesing av volum-konfigurasjon: {e}, bruker normal volum", flush=True)
    
    # Konverter volume_value (0-100) til gain multiplier (0.0-2.0, hvor 1.0 = normal)
    volume_gain = volume_value / 50.0
    
    # Konverter speed_value (0-100) til rate percentage
    # 0 = -50%, 50 = 0%, 100 = +50%
    rate_percent = (speed_value - 50)
    rate_str = f"{rate_percent:+d}%" if rate_percent != 0 else "0%"
    
    print(f"Bruker TTS-stemme: {voice_name}, Nebbet: {'p√•' if beak_enabled else 'av'}, Hastighet: {rate_str}, Volum: {volume_value}% (gain: {volume_gain:.2f})", flush=True)
    
    # Sett h√∏yere lydkvalitet fra Azure (48kHz)
    speech_config.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Riff48Khz16BitMonoPcm
    )
    
    # Bruk SSML med prosody for hastighetskontroll
    ssml = f'<speak version="1.0" xml:lang="nb-NO"><voice name="{voice_name}"><prosody rate="{rate_str}">{text}</prosody></voice></speak>'
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=True) as tmpfile:
        audio_config = speechsdk.audio.AudioOutputConfig(filename=tmpfile.name)
        speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
        result = speech_synthesizer.speak_ssml_async(ssml).get()
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            # Last inn original lyd
            sound = AudioSegment.from_wav(tmpfile.name)
            
            # Konverter til numpy array
            samples_original = np.array(sound.get_array_of_samples(), dtype=np.float32)
            samples_original = samples_original / (2**15)  # Normaliser til -1.0 til 1.0
            
            # Gj√∏r pitch-shift MED tempo endring (for and-stemme)
            # H√∏yere pitch = raskere tempo (som Alvin og gjengen)
            octaves = 0.5  # And-stemme (moderat h√∏yere pitch, fortsatt forst√•elig)
            pitch_factor = 2.0 ** octaves  # ca 1.41x
            
            # Resample til f√¶rre samples = h√∏yere pitch n√•r spilt p√• original sample rate
            new_length = int(len(samples_original) / pitch_factor)
            samples = resample(samples_original, new_length)
            
            # VIKTIG: Vi beholder original framerate, men med f√¶rre samples
            # Dette gir h√∏yere pitch (lyden spilles raskere)
            
            framerate = sound.frame_rate
            n_channels = sound.channels
            sampwidth = sound.sample_width
            
            print(f"After pitch-shift: {framerate} Hz, {n_channels} ch, {sampwidth*8} bit, {len(samples)} samples (var {len(samples_original)})")

            
            # samples er allerede float32 fra pitch-shift
            
            # Sjekk for clipping og normaliser hvis n√∏dvendig
            peak = np.max(np.abs(samples))
            if peak > 0.95:  # Nesten clipping
                print(f"Peak: {peak:.2f} - normaliserer for √• unng√• clipping", flush=True)
                samples = samples / peak * 0.95
            
            # Anvend volum (gain multiplier fra volume_value)
            samples = samples * volume_gain
            
            # Sjekk igjen for clipping etter volum
            peak_after = np.max(np.abs(samples))
            if peak_after > 1.0:
                print(f"Clipping detektert ({peak_after:.2f}) - reduserer volum", flush=True)
                samples = np.clip(samples, -0.99, 0.99)
            
            # Legg til fade-in/fade-out for √• redusere knepp ved start/slutt
            # Sett FADE_MS = 0 i toppen av filen for √• deaktivere
            if FADE_MS > 0:
                fade_samples = int(framerate * FADE_MS / 1000.0)
                if len(samples) > fade_samples * 2:
                    # Fade in
                    fade_in = np.linspace(0, 1, fade_samples)
                    samples[:fade_samples] *= fade_in
                    # Fade out
                    fade_out = np.linspace(1, 0, fade_samples)
                    samples[-fade_samples:] *= fade_out
                    print(f"Anvendt {FADE_MS}ms fade in/out", flush=True)

            # Skal allerede v√¶re 48000 Hz etter pitch-shift
            target_rate = 48000
            if framerate != target_rate:
                print(f"Resampling fra {framerate} Hz til {target_rate} Hz...")
                num_samples_new = int(len(samples) * target_rate / framerate)
                samples = resample(samples, num_samples_new)
                framerate = target_rate
            
            # Low-pass filter deaktivert - kan introdusere artefakter
            # from scipy.signal import butter, filtfilt
            # nyquist = framerate / 2
            # cutoff = 8000  # Kutt av over 8kHz (tale er under dette)
            # b, a = butter(4, cutoff / nyquist, btype='low')
            # samples = filtfilt(b, a, samples)

            # Bruk aplay med dmixer (definert i ~/.asoundrc) for click/pop reduction
            stream_started = False
            
            try:
                # Konverter float32 samples til int16 og lag stereo
                samples_int16 = (samples * 32767).astype(np.int16)
                stereo_samples = np.column_stack([samples_int16, samples_int16])
                
                # Bruk pydub for √• lage WAV
                audio_segment = AudioSegment(
                    stereo_samples.tobytes(),
                    frame_rate=framerate,
                    sample_width=2,  # 16-bit = 2 bytes
                    channels=2
                )
                
                # Eksporter til temp fil og spill med aplay (bruker dmixer fra ~/.asoundrc)
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmpwav:
                    audio_segment.export(tmpwav.name, format='wav')
                    import subprocess
                    import threading
                    
                    # Oppdater nebb i takt med lydniv√• mens aplay kj√∏rer
                    # Hvis nebb er av, bruk LED i stedet
                    chunk_size = int(framerate * BEAK_CHUNK_MS / 1000.0)
                    
                    # Start b√•de aplay og nebb/LED-thread samtidig
                    control_stop = threading.Event()
                    
                    def update_beak_or_led():
                        if BEAK_PRE_START_MS > 0:
                            time.sleep(BEAK_PRE_START_MS / 1000.0)
                        
                        idx = 0
                        start_time = time.time()
                        
                        # Lyden er pitch-shifted (1.41x raskere), s√• juster timing
                        # Faktisk varighet i sekunder
                        actual_duration = len(samples) / framerate
                        
                        while not control_stop.is_set() and idx < len(samples):
                            chunk = samples[idx:idx+chunk_size]
                            if len(chunk) > 0:
                                amp = np.sqrt(np.mean(chunk**2))
                                
                                if beak_enabled and beak:
                                    # Normal nebb-bevegelse
                                    open_pct = min(max(amp * 3.5, 0.05), 1.0)
                                    beak.open_pct(open_pct)
                                else:
                                    # LED-pulsing n√•r nebb er av
                                    intensity = min(amp * 4.0, 1.0)
                                    intensity = max(intensity, 0.1)  # Minimum intensitet
                                    set_intensity(intensity)
                            
                            idx += chunk_size
                            
                            # Beregn n√•r neste oppdatering skal skje basert p√• faktisk tid
                            elapsed = time.time() - start_time
                            target_time = (idx / len(samples)) * actual_duration
                            sleep_time = target_time - elapsed
                            
                            if sleep_time > 0:
                                time.sleep(sleep_time)
                        
                        # Lukk nebbet eller sl√• av LED n√•r ferdig
                        if not control_stop.is_set():
                            if beak_enabled and beak:
                                beak.open_pct(0.05)
                            else:
                                off()  # Sl√• av LED
                    
                    # Start nebb/LED-thread
                    control_thread = threading.Thread(target=update_beak_or_led, daemon=True)
                    control_thread.start()
                    
                    # Start aplay
                    process = subprocess.Popen(['aplay', '-q', tmpwav.name], 
                                              stdout=subprocess.PIPE, 
                                              stderr=subprocess.PIPE)
                    
                    # Vent p√• at aplay er ferdig
                    process.wait()
                    
                    # Stopp nebb/LED-thread
                    control_stop.set()
                    control_thread.join(timeout=1.0)
                    
                    os.unlink(tmpwav.name)
                    
                    if process.returncode == 0:
                        stream_started = True
                    else:
                        stderr = process.stderr.read().decode()
                        print(f"aplay error: {stderr}")
                    
            except Exception as e:
                print(f"dmixer playback error: {e}")
            
            if not stream_started:
                print("Kunne ikke starte lydstr√∏m. Avslutter tale-funksjon uten √• spille av.")
            
            if beak:  # Kun hvis servo er tilgjengelig
                beak.open_pct(0.05)  # Minst 5% √•pen n√•r ferdig
        else:
            print("TTS-feil:", result.reason)
            if hasattr(result, "cancellation_details"):
                print("Detaljer:", result.cancellation_details.reason, result.cancellation_details.error_details)
    # Ikke kall off() eller endre LED her!

def play_song(song_path, beak, speech_config):
    """Spill av en sang med synkronisert nebb-bevegelse"""
    print(f"Spiller sang: {song_path}", flush=True)
    stop_blink()
    
    # Sjekk at mappen finnes
    if not os.path.exists(song_path):
        print(f"Sangmappe finnes ikke: {song_path}", flush=True)
        return
    
    # Finn filene
    mix_file = os.path.join(song_path, "duck_mix.wav")
    vocals_file = os.path.join(song_path, "vocals_duck.wav")
    
    if not os.path.exists(mix_file) or not os.path.exists(vocals_file):
        print(f"Mangler duck_mix.wav eller vocals_duck.wav i {song_path}", flush=True)
        return
    
    # Ekstraher artistnavn og sangtittel fra mappesti
    # Format: "Artist - Sangtittel"
    song_folder_name = os.path.basename(song_path)
    
    # Annonser sangen f√∏r avspilling
    if ' - ' in song_folder_name:
        artist, song_title = song_folder_name.split(' - ', 1)
        announcement = f"N√• skal jeg synge {song_title} av {artist}!"
    else:
        announcement = f"N√• skal jeg synge {song_folder_name}!"
    
    print(f"Annonserer sang: {announcement}", flush=True)
    speak(announcement, speech_config, beak)
    
    # Litt pause f√∏r sang starter
    time.sleep(0.5)
    
    set_red()  # LED r√∏d n√•r anda synger
    
    # Les nebbet-status
    beak_enabled = True
    try:
        if os.path.exists(BEAK_FILE):
            with open(BEAK_FILE, 'r') as f:
                beak_status = f.read().strip()
                beak_enabled = (beak_status != 'off')
    except Exception as e:
        print(f"Feil ved lesing av nebbet-konfigurasjon: {e}, nebbet aktivert", flush=True)
    
    # Les volum (0-100, 50 = normal)
    volume_value = 50
    try:
        if os.path.exists(VOLUME_FILE):
            with open(VOLUME_FILE, 'r') as f:
                vol = f.read().strip()
                if vol:
                    volume_value = int(vol)
    except Exception as e:
        print(f"Feil ved lesing av volum-konfigurasjon: {e}, bruker normal volum", flush=True)
    
    volume_gain = volume_value / 50.0
    
    print(f"Spiller sang med volum: {volume_value}% (gain: {volume_gain:.2f}), Nebbet: {'p√•' if beak_enabled else 'av'}", flush=True)
    
    try:
        # Last inn begge filer
        mix_sound = AudioSegment.from_wav(mix_file)
        vocals_sound = AudioSegment.from_wav(vocals_file)
        
        # Sjekk at de er like lange (ca)
        if abs(len(mix_sound) - len(vocals_sound)) > 1000:  # 1 sekund toleranse
            print(f"Advarsel: Mix og vocals har ulik lengde ({len(mix_sound)}ms vs {len(vocals_sound)}ms)", flush=True)
        
        # Konverter mix til numpy array for avspilling
        mix_samples = np.array(mix_sound.get_array_of_samples(), dtype=np.float32)
        mix_samples = mix_samples / (2**15)  # Normaliser til -1.0 til 1.0
        
        # Anvend volum
        mix_samples = mix_samples * volume_gain
        
        # Sjekk om audio er stereo og reshape hvis n√∏dvendig
        n_channels = mix_sound.channels
        framerate = mix_sound.frame_rate
        
        print(f"Audio format: {framerate} Hz, {n_channels} kanal(er), {len(mix_samples)} samples", flush=True)
        
        # Hvis stereo, reshape til (samples, 2)
        if n_channels == 2:
            mix_samples = mix_samples.reshape(-1, 2)
        else:
            # Mono, reshape til (samples, 1) for konsistens
            mix_samples = mix_samples.reshape(-1, 1)
        
        # Konverter vocals til numpy array for amplitude detection
        vocals_samples = np.array(vocals_sound.get_array_of_samples(), dtype=np.float32)
        vocals_samples = vocals_samples / (2**15)
        
        # Vocals skal alltid v√¶re mono for amplitude detection
        if vocals_sound.channels == 2:
            # Konverter stereo til mono (gjennomsnitt av venstre og h√∏yre)
            vocals_samples = vocals_samples.reshape(-1, 2).mean(axis=1)
        
        # Finn output device
        output_device = find_hifiberry_output()
        
        # Avspilling med sounddevice
        chunk_size = int(framerate * BEAK_CHUNK_MS / 1000.0)
        mix_idx = 0
        
        # Beregn lengder for synkronisering
        # mix_samples kan v√¶re (N, 2) for stereo eller (N, 1) for mono
        # vocals_samples er alltid flat mono array
        total_frames = len(mix_samples)  # Antall frames i mix
        vocals_length = len(vocals_samples)  # Antall samples i vocals
        
        # Flag for stopp
        song_stopped = False
        
        # Nebb-tr√•d
        nebb_stop = threading.Event()
        led_stop = threading.Event()
        
        def beak_controller():
            nonlocal mix_idx, song_stopped
            while not nebb_stop.is_set() and not song_stopped:
                # Sjekk for stopp-foresp√∏rsel
                if os.path.exists(SONG_STOP_FILE):
                    try:
                        os.remove(SONG_STOP_FILE)
                        print("Sang stoppet av bruker", flush=True)
                        song_stopped = True
                        nebb_stop.set()
                        break
                    except:
                        pass
                
                # Beregn vocals position basert p√• mix playback progress
                # mix_idx er frame index, vocals trenger sample index
                if total_frames > 0:
                    progress = min(mix_idx / total_frames, 1.0)
                    vocals_pos = int(progress * vocals_length)
                    vocals_pos = min(vocals_pos, vocals_length - chunk_size)
                    
                    if vocals_pos >= 0 and vocals_pos < vocals_length:
                        chunk = vocals_samples[vocals_pos:vocals_pos+chunk_size]
                        if len(chunk) > 0:
                            amp = np.sqrt(np.mean(chunk**2))
                            open_pct = min(max(amp * 3.5, 0.05), 1.0)
                            beak.open_pct(open_pct)
                
                time.sleep(BEAK_CHUNK_MS / 1000.0)
        
        def led_controller():
            """LED blinker i takt med musikken"""
            nonlocal mix_idx, song_stopped
            
            # For LED, bruk mix audio (kan v√¶re stereo)
            # Hvis stereo, konverter til mono for amplitude
            if n_channels == 2:
                mix_mono = mix_samples.mean(axis=1)  # Gjennomsnitt av venstre og h√∏yre
            else:
                mix_mono = mix_samples.flatten()
            
            while not led_stop.is_set() and mix_idx < len(mix_mono):
                # Sjekk for stopp
                if song_stopped:
                    break
                
                # Bruk mix_idx for √• lese riktig posisjon
                # (mix_idx oppdateres av playback thread)
                current_pos = min(mix_idx, len(mix_mono) - 1)
                chunk = mix_mono[current_pos:current_pos+chunk_size]
                if len(chunk) > 0:
                    amp = np.sqrt(np.mean(np.abs(chunk)**2))
                    # Skaler amplitude til 0.0-1.0 range, med litt boost
                    intensity = min(amp * 4.0, 1.0)
                    # Sett minimum intensitet s√• LED ikke slukker helt
                    intensity = max(intensity, 0.1)
                    set_intensity(intensity)
                
                time.sleep(BEAK_CHUNK_MS / 1000.0)
        
        # Start nebb og LED tr√•der
        if beak_enabled and beak:
            beak_thread = threading.Thread(target=beak_controller, daemon=True)
            beak_thread.start()
        
        led_thread = threading.Thread(target=led_controller, daemon=True)
        led_thread.start()
        
        # Spill av mix med sounddevice (blocking)
        with sd.OutputStream(samplerate=framerate, channels=n_channels, device=output_device, dtype='float32') as stream:
            while mix_idx < len(mix_samples) and not song_stopped:
                # Sjekk for stopp-foresp√∏rsel i main thread ogs√•
                if os.path.exists(SONG_STOP_FILE):
                    try:
                        os.remove(SONG_STOP_FILE)
                        print("Sang stoppet av bruker (main thread)", flush=True)
                        song_stopped = True
                        break
                    except:
                        pass
                
                chunk = mix_samples[mix_idx:mix_idx+4096]
                if len(chunk) < 4096:
                    # Pad siste chunk med stillhet
                    if n_channels == 2:
                        chunk = np.pad(chunk, ((0, 4096 - len(chunk)), (0, 0)), mode='constant')
                    else:
                        chunk = np.pad(chunk, ((0, 4096 - len(chunk)), (0, 0)), mode='constant')
                
                stream.write(chunk)
                mix_idx += 4096
        
        # Stopp nebb og LED tr√•der
        if beak_enabled and beak:
            nebb_stop.set()
            beak_thread.join(timeout=1.0)
        
        led_stop.set()
        led_thread.join(timeout=1.0)
        
        # Lukk nebbet litt og reset LED til r√∏d
        if beak:
            beak.open_pct(0.05)
        set_red()  # Tilbake til r√∏d LED
        if beak:
            beak.open_pct(0.05)
        
        print("Sang ferdig!", flush=True)
        
    except Exception as e:
        print(f"Feil ved avspilling av sang: {e}", flush=True)
        import traceback
        traceback.print_exc()

def recognize_speech_from_mic(device_name=None):
    set_green()  # LED gr√∏nn mens bruker snakker
    stt_key = os.getenv("AZURE_STT_KEY")
    stt_region = os.getenv("AZURE_STT_REGION")
    silence_timeout = os.getenv("AZURE_STT_SILENCE_TIMEOUT_MS", "1200")  # Default 1200ms hvis ikke satt
    speech_config = speechsdk.SpeechConfig(subscription=stt_key, region=stt_region)
    
    # Finn USB mikrofon dynamisk (ALSA card kan endre seg ved reboot)
    usb_alsa_device = find_usb_mic_alsa_card()
    devices_to_try = [usb_alsa_device, "default"]  # plughw gir bedre kompatibilitet enn hw
    
    for attempt, dev in enumerate(devices_to_try):
        try:
            print(f"Pr√∏ver Azure STT med device: {dev}", flush=True)
            audio_config = speechsdk.audio.AudioConfig(device_name=dev)
            speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config, language="nb-NO")
            prop = speechsdk.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
            speech_recognizer.properties.set_property(prop, silence_timeout)
            print(f"Snakk n√• (device {dev}, timeout {silence_timeout}ms)...", flush=True)
            t0 = time.time()
            result = speech_recognizer.recognize_once()
            t1 = time.time()
            elapsed = t1 - t0
            print(f"Azure STT tid: {elapsed:.2f} sekunder", flush=True)
            off()  # Sl√• av LED etter bruker har snakket
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                print(f"Du sa: {result.text}", flush=True)
                return result.text
            elif result.reason == speechsdk.ResultReason.NoMatch:
                print("Ingen tale gjenkjent.", flush=True)
                return None
            else:
                print(f"Talegjenkjenning feilet: {result.reason}", flush=True)
                return None
        except Exception as e:
            print(f"Azure STT feil med device {dev}: {e}", flush=True)
            if attempt < len(devices_to_try) - 1:
                print(f"Pr√∏ver neste device...", flush=True)
                time.sleep(0.5)
                continue
            else:
                print("Alle devices feilet", flush=True)
                off()
                return None

def control_hue_lights(action, room=None, brightness=None, color=None):
    """
    Kontroller Philips Hue smarte lys
    
    Args:
        action: "on", "off", "dim", "brighten" 
        room: Navnet p√• rommet/lyset (None = alle lys)
        brightness: 0-100 (prosent)
        color: "r√∏d", "bl√•", "gr√∏nn", "gul", "hvit", "rosa", "lilla", "oransje"
    """
    try:
        bridge_ip = os.getenv("HUE_BRIDGE_IP")
        api_key = os.getenv("HUE_API_KEY")
        
        if not bridge_ip or not api_key:
            return "Philips Hue er ikke konfigurert. Legg til HUE_BRIDGE_IP og HUE_API_KEY i .env"
        
        base_url = f"http://{bridge_ip}/api/{api_key}"
        
        # Hent alle lys
        response = requests.get(f"{base_url}/lights", timeout=5)
        response.raise_for_status()
        lights = response.json()
        
        if not lights:
            return "Fant ingen Philips Hue-lys p√• nettverket."
        
        # Finn hvilke lys som skal styres
        target_lights = []
        if room:
            # S√∏k etter lys som matcher romnavnet
            room_lower = room.lower()
            for light_id, light_data in lights.items():
                light_name = light_data.get('name', '').lower()
                if room_lower in light_name:
                    target_lights.append((light_id, light_data['name']))
            
            if not target_lights:
                return f"Fant ingen lys som matcher '{room}'. Tilgjengelige lys: {', '.join([lights[lid]['name'] for lid in lights])}"
        else:
            # Alle lys
            target_lights = [(lid, lights[lid]['name']) for lid in lights]
        
        # Fargekart (Hue format: 0-65535)
        color_map = {
            'r√∏d': {'hue': 0, 'sat': 254},
            'oransje': {'hue': 5000, 'sat': 254},
            'gul': {'hue': 12000, 'sat': 254},
            'gr√∏nn': {'hue': 25500, 'sat': 254},
            'cyan': {'hue': 35000, 'sat': 254},
            'bl√•': {'hue': 46920, 'sat': 254},
            'lilla': {'hue': 50000, 'sat': 254},
            'rosa': {'hue': 56100, 'sat': 254},
            'hvit': {'sat': 0, 'ct': 366}  # Varm hvit
        }
        
        # Bygg state-objektet
        state = {}
        
        if action == "on":
            state['on'] = True
            if brightness is not None:
                state['bri'] = int(brightness * 254 / 100)  # Konverter 0-100 til 0-254
            if color and color.lower() in color_map:
                state.update(color_map[color.lower()])
        
        elif action == "off":
            state['on'] = False
        
        elif action == "dim":
            current_bri = 100  # Default
            state['on'] = True
            if brightness:
                state['bri'] = int(brightness * 254 / 100)
            else:
                state['bri'] = 50  # 20% lysstyrke
        
        elif action == "brighten":
            state['on'] = True
            if brightness:
                state['bri'] = int(brightness * 254 / 100)
            else:
                state['bri'] = 254  # Full lysstyrke
        
        # Utf√∏r kommandoen p√• alle target lys
        results = []
        for light_id, light_name in target_lights:
            try:
                url = f"{base_url}/lights/{light_id}/state"
                resp = requests.put(url, json=state, timeout=5)
                resp.raise_for_status()
                results.append(light_name)
            except Exception as e:
                print(f"Feil ved kontroll av {light_name}: {e}", flush=True)
        
        # Bygg svar
        action_desc = {
            'on': 'skrudd p√•',
            'off': 'skrudd av',
            'dim': 'dimmet',
            'brighten': 'gjort lysere'
        }.get(action, action)
        
        if results:
            result_msg = f"Jeg har {action_desc} {len(results)} lys: {', '.join(results)}"
            if brightness:
                result_msg += f" til {brightness}%"
            if color:
                result_msg += f" ({color} farge)"
            return result_msg
        else:
            return f"Kunne ikke kontrollere noen lys."
        
    except Exception as e:
        print(f"Hue-kontroll feil: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return f"Beklager, jeg kunne ikke kontrollere Hue-lysene akkurat n√•. Feil: {str(e)}"

def control_beak(enabled):
    """Sl√• nebb p√• eller av"""
    try:
        status = "on" if enabled else "off"
        with open(BEAK_FILE, 'w') as f:
            f.write(status)
        
        action = "p√•" if enabled else "av"
        return f"Jeg har skrudd nebbet {action}. {'Jeg bruker LED-lys i stedet n√•r jeg snakker.' if not enabled else 'N√• beveger nebbet seg n√•r jeg snakker.'}"
    except Exception as e:
        print(f"Feil ved nebb-kontroll: {e}", flush=True)
        return f"Beklager, jeg kunne ikke endre nebb-innstillingen. Feil: {str(e)}"

def get_ip_address_tool():
    """Hent n√•v√¶rende IP-adresse for Pi'en"""
    try:
        import socket
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.settimeout(2)
        s.connect(("8.8.8.8", 80))
        ip_address = s.getsockname()[0]
        s.close()
        
        if ip_address and ip_address != "127.0.0.1":
            # Formater IP-adresse for tale
            ip_spoken = ip_address.replace('.', ' punkt ')
            return f"Min IP-adresse er {ip_spoken}. Du finner kontrollpanelet p√• port 3000, alts√•: http://{ip_address}:3000"
        else:
            return "Jeg kunne ikke finne en gyldig IP-adresse. Jeg er kanskje ikke koblet til et nettverk."
    except Exception as e:
        print(f"Feil ved henting av IP-adresse: {e}", flush=True)
        return "Beklager, jeg kunne ikke hente IP-adressen min akkurat n√•. Sjekk at jeg er koblet til nettverket."

def is_conversation_ending(user_text: str) -> bool:
    """
    Sjekker om brukerens input indikerer at de vil avslutte samtalen.
    Returnerer True hvis input er en avslutningsfrase.
    """
    text_lower = user_text.strip().lower()
    
    # Fjern vanlig tegnsetting
    text_clean = text_lower.replace(".", "").replace(",", "").replace("!", "").replace("?", "")
    
    # Liste over avslutningsfraser
    ending_phrases = [
        "nei takk",
        "nei det er greit",
        "nei det er bra",
        "nei det er fint",
        "nei det holder",
        "det er alt",
        "det er greit",
        "det er bra",
        "det er fint",
        "det holder",
        "stopp"  # Eksplisitt stopp-kommando
    ]
    
    # Sjekk ogs√• for enkelt "takk" eller "nei" hvis det er hele meldingen
    if text_clean in ["takk", "tusen takk", "mange takk", "nei", "stopp"]:
        return True
    
    # Sjekk om noen av frasene matcher
    for phrase in ending_phrases:
        if phrase in text_clean:
            return True
    
    return False

def generate_message_metadata(user_text: str, ai_response: str) -> dict:
    """
    Generer metadata for en melding (enkelt, uten LLM for ytelse)
    Returnerer: {
        'user_length': int,
        'ai_length': int,
        'has_question': bool,
        'topics_mentioned': list,
        'timestamp': str
    }
    """
    metadata = {
        'user_length': len(user_text),
        'ai_length': len(ai_response),
        'has_question': '?' in user_text,
        'timestamp': datetime.now().isoformat()
    }
    
    # Enkel topic detection basert p√• keywords
    topics = []
    user_lower = user_text.lower()
    
    # Kategori-mapping
    topic_keywords = {
        'weather': ['v√¶r', 'temperatur', 'regn', 'sol', 'varmt', 'kaldt'],
        'time': ['klokk', 'tid', 'dato', 'dag', 'm√•ned', '√•r'],
        'family': ['mamma', 'pappa', 's√∏ster', 'bror', 'familie', 'barn', 'datter', 's√∏nn'],
        'work': ['jobb', 'arbeid', 'kontor', 'm√∏te', 'kollega', 'sjef'],
        'health': ['lege', 'syk', 'tannlege', 'time', 'smerter', 'vondt'],
        'home': ['hus', 'leilighet', 'rom', 'kj√∏kken', 'bad', 'soverom'],
        'food': ['mat', 'middag', 'lunsj', 'frokost', 'spise', 'sultne'],
        'music': ['sang', 'musikk', 'spill', 'syng', 'l√•t'],
        'lights': ['lys', 'lampe', 'skru p√•', 'skru av', 'dimme']
    }
    
    for topic, keywords in topic_keywords.items():
        if any(keyword in user_lower for keyword in keywords):
            topics.append(topic)
    
    metadata['topics'] = topics if topics else ['general']
    
    # Enkelt importance score basert p√• lengde og sp√∏rsm√•l
    importance = 5  # Base importance
    if metadata['has_question']:
        importance += 2
    if metadata['user_length'] > 100:
        importance += 1
    if len(topics) > 0:
        importance += 1
    
    metadata['importance'] = min(importance, 10)
    
    return metadata

def get_coordinates(location_name):
    """Hent koordinater for et stedsnavn - sjekker f√∏rst lokal database, deretter Nominatim"""
    try:
        # F√∏rst: Sjekk om stedet finnes i v√•r lokale database
        locations_file = "/home/admog/Code/chatgpt-and/locations.json"
        if os.path.exists(locations_file):
            try:
                with open(locations_file, 'r', encoding='utf-8') as f:
                    locations_data = json.load(f)
                    locations = locations_data.get('locations', {})
                    
                    # S√∏k case-insensitive
                    location_key = location_name.lower().strip()
                    if location_key in locations:
                        loc = locations[location_key]
                        print(f"üìç Bruker lokal koordinat for {loc['name']}", flush=True)
                        return loc['lat'], loc['lon'], loc['description']
            except Exception as e:
                print(f"Kunne ikke lese locations.json: {e}", flush=True)
        
        # Fallback: S√∏k via Nominatim (OpenStreetMap)
        search_query = f"{location_name}, Norge"
        url = "https://nominatim.openstreetmap.org/search"
        params = {
            'q': search_query,
            'format': 'json',
            'limit': 1
        }
        headers = {
            'User-Agent': 'ChatGPTDuck/2.1.2 (contact: github.com/osmund/chatgpt-and)'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        if data and len(data) > 0:
            lat = float(data[0]['lat'])
            lon = float(data[0]['lon'])
            display_name = data[0].get('display_name', location_name)
            print(f"üìç Bruker Nominatim for {location_name}", flush=True)
            return lat, lon, display_name
        return None
    except Exception as e:
        print(f"Geocoding feil for '{location_name}': {e}", flush=True)
        return None

def get_weather(location_name, timeframe="now"):
    """
    Hent v√¶rmelding fra yr.no (MET Norway API)
    Returnerer temperatur og v√¶rbeskrivelse for angitt tidsramme
    
    Args:
        location_name: Navn p√• stedet
        timeframe: "now" (n√•), "today" (i dag), "tomorrow" (i morgen)
    """
    try:
        # F√∏rst: Finn koordinater for stedet
        coords = get_coordinates(location_name)
        if not coords:
            return f"Beklager, jeg fant ikke stedet '{location_name}'."
        
        lat, lon, display_name = coords
        print(f"V√¶rdata for {display_name} (lat: {lat}, lon: {lon}), tidsramme: {timeframe}", flush=True)
        
        # Hent v√¶rdata fra MET Norway locationforecast API
        url = "https://api.met.no/weatherapi/locationforecast/2.0/compact"
        params = {'lat': lat, 'lon': lon}
        headers = {
            'User-Agent': 'ChatGPTDuck/2.1.2 (contact: github.com/osmund/chatgpt-and)'
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # Parse v√¶rdata
        timeseries = data['properties']['timeseries']
        
        # Oversett symbolkoder til norsk
        symbol_translations = {
            'clearsky': 'klarv√¶r',
            'cloudy': 'overskyet',
            'fair': 'lettskyet',
            'fog': 't√•ke',
            'heavyrain': 'kraftig regn',
            'heavyrainandthunder': 'kraftig regn og torden',
            'heavyrainshowers': 'kraftige regnbyger',
            'heavysleet': 'kraftig sludd',
            'heavysleetandthunder': 'kraftig sludd og torden',
            'heavysnow': 'kraftig sn√∏',
            'heavysnowandthunder': 'kraftig sn√∏ og torden',
            'heavysnowshowers': 'kraftige sn√∏byger',
            'lightrain': 'lett regn',
            'lightrainandthunder': 'lett regn og torden',
            'lightrainshowers': 'lette regnbyger',
            'lightsleet': 'lett sludd',
            'lightsleetandthunder': 'lett sludd og torden',
            'lightsnow': 'lett sn√∏',
            'lightsnowandthunder': 'lett sn√∏ og torden',
            'lightsnowshowers': 'lette sn√∏byger',
            'partlycloudy': 'delvis skyet',
            'rain': 'regn',
            'rainandthunder': 'regn og torden',
            'rainshowers': 'regnbyger',
            'sleet': 'sludd',
            'sleetandthunder': 'sludd og torden',
            'sleetshowers': 'sluddbyger',
            'snow': 'sn√∏',
            'snowandthunder': 'sn√∏ og torden',
            'snowshowers': 'sn√∏byger'
        }
        
        def get_weather_desc(symbol_code):
            symbol_base = symbol_code.split('_')[0]
            return symbol_translations.get(symbol_base, symbol_code)
        
        now = datetime.now()
        
        if timeframe == "tomorrow":
            # Finn v√¶rdatafor i morgen
            tomorrow_date = (now + timedelta(days=1)).date()
            
            # Samle data for morgendagen
            tomorrow_temps = []
            tomorrow_symbols = []
            tomorrow_winds = []
            
            for ts in timeseries:
                ts_time = datetime.fromisoformat(ts['time'].replace('Z', '+00:00'))
                if ts_time.date() == tomorrow_date:
                    temp = ts['data']['instant']['details']['air_temperature']
                    tomorrow_temps.append(temp)
                    
                    # Hent vindstyrke
                    wind = ts['data']['instant']['details'].get('wind_speed', 0)
                    tomorrow_winds.append(wind)
                    
                    # Hent v√¶rsymbol hvis tilgjengelig
                    if 'next_1_hours' in ts['data']:
                        tomorrow_symbols.append(ts['data']['next_1_hours']['summary']['symbol_code'])
                    elif 'next_6_hours' in ts['data']:
                        tomorrow_symbols.append(ts['data']['next_6_hours']['summary']['symbol_code'])
            
            if not tomorrow_temps:
                return f"Beklager, jeg har ikke v√¶rdata for i morgen for {display_name}."
            
            # Beregn min/max temp og gjennomsnittsvind
            min_temp = min(tomorrow_temps)
            max_temp = max(tomorrow_temps)
            avg_wind = sum(tomorrow_winds) / len(tomorrow_winds) if tomorrow_winds else 0
            max_wind = max(tomorrow_winds) if tomorrow_winds else 0
            
            # Beskriv vindstyrke p√• norsk
            def get_wind_description(speed_ms):
                if speed_ms < 1.6:
                    return "vindstille"
                elif speed_ms < 3.4:
                    return "svak vind"
                elif speed_ms < 5.5:
                    return "lett bris"
                elif speed_ms < 8.0:
                    return "laber bris"
                elif speed_ms < 10.8:
                    return "frisk bris"
                elif speed_ms < 13.9:
                    return "liten kuling"
                elif speed_ms < 17.2:
                    return "stiv kuling"
                elif speed_ms < 20.8:
                    return "sterk kuling"
                elif speed_ms < 24.5:
                    return "liten storm"
                elif speed_ms < 28.5:
                    return "full storm"
                else:
                    return "sterk storm"
            
            wind_desc = get_wind_description(avg_wind)
            
            # Finn mest vanlige v√¶rsymbol
            most_common_symbol = "ukjent"
            if tomorrow_symbols:
                from collections import Counter
                most_common_symbol = Counter(tomorrow_symbols).most_common(1)[0][0]
            
            weather_desc = get_weather_desc(most_common_symbol)
            
            # Hent total nedb√∏r for morgendagen
            total_precipitation = 0
            for ts in timeseries:
                ts_time = datetime.fromisoformat(ts['time'].replace('Z', '+00:00'))
                if ts_time.date() == tomorrow_date:
                    if 'next_1_hours' in ts['data'] and 'details' in ts['data']['next_1_hours']:
                        precip = ts['data']['next_1_hours']['details'].get('precipitation_amount', 0)
                        total_precipitation += precip
            
            result = f"V√¶rmelding for {display_name} i morgen:\n"
            result += f"Temperatur: {min_temp:.1f}¬∞C til {max_temp:.1f}¬∞C\n"
            result += f"V√¶r: {weather_desc}\n"
            result += f"Vind: {wind_desc} (gjennomsnitt {avg_wind:.1f} m/s, maks {max_wind:.1f} m/s)\n"
            
            # Legg til nedb√∏r hvis relevant
            if total_precipitation > 0.1:
                result += f"Nedb√∏r: {total_precipitation:.1f} mm"
            else:
                result += "Ingen nedb√∏r ventet"
            
        else:  # "now" eller "today"
            # N√•v√¶rende v√¶r (f√∏rste tidspunkt)
            current = timeseries[0]['data']['instant']['details']
            current_temp = current['air_temperature']
            
            # Hent vinddata
            wind_speed = current.get('wind_speed', 0)  # m/s
            wind_from_direction = current.get('wind_from_direction', None)  # grader
            
            # Konverter vindretning fra grader til kompassretning
            def get_wind_direction(degrees):
                if degrees is None:
                    return ""
                directions = ["nord", "nord√∏st", "√∏st", "s√∏r√∏st", "s√∏r", "s√∏rvest", "vest", "nordvest"]
                index = round(degrees / 45) % 8
                return directions[index]
            
            # Beskriv vindstyrke p√• norsk (basert p√• Beaufort-skala)
            def get_wind_description(speed_ms):
                if speed_ms < 1.6:
                    return "vindstille"
                elif speed_ms < 3.4:
                    return "svak vind"
                elif speed_ms < 5.5:
                    return "lett bris"
                elif speed_ms < 8.0:
                    return "laber bris"
                elif speed_ms < 10.8:
                    return "frisk bris"
                elif speed_ms < 13.9:
                    return "liten kuling"
                elif speed_ms < 17.2:
                    return "stiv kuling"
                elif speed_ms < 20.8:
                    return "sterk kuling"
                elif speed_ms < 24.5:
                    return "liten storm"
                elif speed_ms < 28.5:
                    return "full storm"
                else:
                    return "sterk storm"
            
            wind_desc = get_wind_description(wind_speed)
            wind_dir = get_wind_direction(wind_from_direction)
            wind_text = f"{wind_desc}"
            if wind_dir and wind_speed >= 1.6:  # Kun vis retning hvis det er vind
                wind_text += f" fra {wind_dir}"
            wind_text += f" ({wind_speed:.1f} m/s)"
            
            # Finn symbolkode for n√•v√¶rende v√¶r
            current_symbol = "ukjent"
            if 'next_1_hours' in timeseries[0]['data']:
                current_symbol = timeseries[0]['data']['next_1_hours']['summary']['symbol_code']
            elif 'next_6_hours' in timeseries[0]['data']:
                current_symbol = timeseries[0]['data']['next_6_hours']['summary']['symbol_code']
            
            weather_desc = get_weather_desc(current_symbol)
            
            # Hent nedb√∏r neste time og neste 6 timer
            precip_1h = 0
            precip_6h = 0
            if 'next_1_hours' in timeseries[0]['data'] and 'details' in timeseries[0]['data']['next_1_hours']:
                precip_1h = timeseries[0]['data']['next_1_hours']['details'].get('precipitation_amount', 0)
            if 'next_6_hours' in timeseries[0]['data'] and 'details' in timeseries[0]['data']['next_6_hours']:
                precip_6h = timeseries[0]['data']['next_6_hours']['details'].get('precipitation_amount', 0)
            
            # Hent prognose for resten av dagen (neste 6-12 timer)
            forecast_summary = []
            for i in range(1, min(13, len(timeseries))):  # Neste 12 timer
                ts = timeseries[i]
                time_str = ts['time']
                temp = ts['data']['instant']['details']['air_temperature']
                
                # Hent hver 3. time for √• ikke overbelaste
                if i % 3 == 0:
                    hour = time_str.split('T')[1][:5]
                    forecast_summary.append(f"{hour}: {temp:.1f}¬∞C")
            
            # Bygg svar
            result = f"V√¶rmelding for {display_name}:\n"
            result += f"N√•: {current_temp:.1f}¬∞C, {weather_desc}\n"
            result += f"Vind: {wind_text}\n"
            
            # Legg til nedb√∏r-informasjon
            if precip_1h > 0.1:
                result += f"Nedb√∏r neste time: {precip_1h:.1f} mm\n"
            elif precip_6h > 0.1:
                result += f"Nedb√∏r neste 6 timer: {precip_6h:.1f} mm\n"
            else:
                result += "Ingen nedb√∏r ventet\n"
            
            if forecast_summary:
                result += f"Prognose i dag: {', '.join(forecast_summary[:4])}"  # Max 4 tidspunkt
        
        return result
        
    except Exception as e:
        print(f"V√¶rhenting feil: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return f"Beklager, jeg kunne ikke hente v√¶rdata akkurat n√•. Feil: {str(e)}"

def chatgpt_query(messages, api_key, model=None, memory_manager=None, user_manager=None):
    if model is None:
        # Pr√∏v √• lese modell fra konfigurasjonsfil
        try:
            if os.path.exists(MODEL_CONFIG_FILE):
                with open(MODEL_CONFIG_FILE, 'r') as f:
                    model = f.read().strip()
                    if not model:
                        model = DEFAULT_MODEL
            else:
                model = DEFAULT_MODEL
        except Exception as e:
            print(f"Feil ved lesing av modellkonfigurasjon: {e}, bruker default", flush=True)
            model = DEFAULT_MODEL
    
    print(f"Bruker AI-modell: {model}", flush=True)
    
    # Hent n√•v√¶rende bruker
    current_user = None
    if user_manager:
        try:
            current_user = user_manager.get_current_user()
            print(f"üë§ N√•v√¶rende bruker: {current_user['display_name']} ({current_user['relation']})", flush=True)
        except Exception as e:
            print(f"‚ö†Ô∏è Kunne ikke hente current_user: {e}", flush=True)
    
    # Les personlighet fra konfigurasjonsfil
    personality_prompt = None
    try:
        # Last personligheter fra JSON-fil
        personalities_file = "/home/admog/Code/chatgpt-and/personalities.json"
        personalities = {}
        if os.path.exists(personalities_file):
            with open(personalities_file, 'r', encoding='utf-8') as f:
                personalities = json.load(f)
        
        # Les hvilken personlighet som skal brukes
        if os.path.exists(PERSONALITY_FILE):
            with open(PERSONALITY_FILE, 'r', encoding='utf-8') as f:
                personality = f.read().strip()
                personality_prompt = personalities.get(personality, "")
    except Exception as e:
        print(f"Feil ved lesing av personlighet: {e}", flush=True)
    
    # Last messages.json for ending_phrases
    messages_config_local = None
    try:
        messages_file = "/home/admog/Code/chatgpt-and/messages.json"
        if os.path.exists(messages_file):
            with open(messages_file, 'r', encoding='utf-8') as f:
                messages_config_local = json.load(f)
    except Exception as e:
        print(f"Feil ved lesing av messages.json: {e}", flush=True)
    
    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # Hent n√•v√¶rende dato og tid fra system
    now = datetime.now()
    
    # Norske navn for dager og m√•neder
    norwegian_days = {
        'Monday': 'mandag',
        'Tuesday': 'tirsdag', 
        'Wednesday': 'onsdag',
        'Thursday': 'torsdag',
        'Friday': 'fredag',
        'Saturday': 'l√∏rdag',
        'Sunday': 's√∏ndag'
    }
    
    norwegian_months = {
        'January': 'januar',
        'February': 'februar',
        'March': 'mars',
        'April': 'april',
        'May': 'mai',
        'June': 'juni',
        'July': 'juli',
        'August': 'august',
        'September': 'september',
        'October': 'oktober',
        'November': 'november',
        'December': 'desember'
    }
    
    # Bygg norsk dato-string manuelt
    day_name = norwegian_days[now.strftime('%A')]
    month_name = norwegian_months[now.strftime('%B')]
    date_time_info = f"N√•v√¶rende dato og tid: {day_name} {now.day}. {month_name} {now.year}, klokken {now.strftime('%H:%M')}. "
    
    # Legg til brukerinfo hvis tilgjengelig
    user_info = ""
    if current_user:
        user_info = f"\n\n### N√•v√¶rende bruker ###\n"
        user_info += f"Du snakker n√• med: {current_user['display_name']}\n"
        user_info += f"Relasjon til Osmund (primary user): {current_user['relation']}\n"
        
        if current_user['username'] != 'Osmund':
            timeout_sec = user_manager.get_time_until_timeout()
            if timeout_sec:
                timeout_min = timeout_sec // 60
                user_info += f"Viktig: Hvis brukeren ikke svarer p√• 30 minutter, vil systemet automatisk bytte tilbake til Osmund.\n"
    
    # Legg til dato/tid + personlighet i system-prompt
    final_messages = messages.copy()
    system_content = date_time_info + user_info
    
    # Samle memory context f√∏rst (men legg til senere)
    memory_section = ""
    if memory_manager:
        try:
            # Hent brukerens siste melding for relevant s√∏k
            user_query = messages[-1]["content"] if messages else ""
            context = memory_manager.build_context_for_ai(user_query, recent_messages=3)
            
            # Bygg memory section (legges til senere)
            memory_section = "\n\n### Ditt Minne ###\n"
            
            # Profile facts
            if context['profile_facts']:
                memory_section += "Fakta om brukeren:\n"
                for fact in context['profile_facts']:  # Vis alle facts (√∏kt til 40)
                    memory_section += f"- {fact['key']}: {fact['value']}"
                    
                    # Vis metadata hvis tilgjengelig og relevant
                    if fact.get('metadata') and fact['metadata']:
                        meta = fact['metadata']
                        # Parse JSON hvis det er en string
                        if isinstance(meta, str):
                            try:
                                meta = json.loads(meta)
                            except:
                                meta = {}
                        
                        # Vis kun relevante metadata-felt
                        if 'learned_at' in meta:
                            learned_date = meta['learned_at'].split('T')[0]
                            memory_section += f" (l√¶rt {learned_date})"
                        if 'verified' in meta and meta['verified']:
                            memory_section += " [verifisert]"
                    
                    memory_section += "\n"
                
                memory_section += "\nViktig: N√•r du refererer til familiemedlemmer, ALLTID bruk deres navn i stedet for 's√∏ster 1/2/3' eller 'din andre s√∏ster'. Dette gj√∏r samtalen mer personlig og naturlig.\n"
                memory_section += "\nOBS: Datoer i formatet 'DD-MM' er dag-m√•ned (f.eks. '21-11' = 21. november). N√•r du svarer om f√∏dselsdager, inkluder b√•de dag og m√•ned.\n"
                
                # Bygg eksplisitt oversikt over s√∏strene direkte fra databasen (ikke kontekst) 
                # for √• sikre at ALLE s√∏stre inkluderes
                sisters = {}
                conn = memory_manager._get_connection()
                c = conn.cursor()
                c.execute("SELECT key, value FROM profile_facts WHERE key IN ('sister_1_name', 'sister_2_name', 'sister_3_name', 'sister_1_age_relation', 'sister_2_age_relation', 'sister_3_age_relation')")
                for row in c.fetchall():
                    key = row[0]
                    value = row[1]
                    sister_num = key.split('_')[1]
                    if sister_num not in sisters:
                        sisters[sister_num] = {}
                    if key.endswith('_name'):
                        sisters[sister_num]['name'] = value
                    elif key.endswith('_age_relation'):
                        sisters[sister_num]['age_relation'] = value
                conn.close()
                
                if sisters:
                    memory_section += "\nKRITISK - S√∏strene (bruk ALLTID denne informasjonen):\n"
                    for num, info in sorted(sisters.items()):
                        if 'name' in info and 'age_relation' in info:
                            memory_section += f"- {info['name']} er den {info['age_relation']} s√∏steren\n"

            
            # Relevant memories
            if context['relevant_memories']:
                memory_section += "\n### Relevante minner ###\n"
                memory_section += "Dette husker du fra tidligere samtaler:\n\n"
                for mem_text, score in context['relevant_memories'][:5]:  # Top 5 memories
                    # Konverter tredjeperson til f√∏rsteperson for bedre forst√•else
                    converted = mem_text
                    converted = converted.replace("Brukeren", "Du")
                    converted = converted.replace("brukeren", "du")
                    converted = converted.replace("Anda", "meg")
                    # Juster verbformer hvis n√∏dvendig
                    if converted.startswith("Du "):
                        # "Du planlegger" -> OK
                        # "Du skal" -> OK
                        # "Du lastet" -> "Du lastet" (OK)
                        pass
                    memory_section += f"- {converted}\n"
                memory_section += "\nBruk denne informasjonen n√•r du svarer!\n"
            
            # Recent topics
            if context['recent_topics']:
                topics = [t['topic'] for t in context['recent_topics'][:3]]
                memory_section += f"\nSiste emner vi har snakket om: {', '.join(topics)}\n"
            
            # IKKE legg til memory_section her enn√•
            print(f"‚úÖ Memory context bygget ({len(context['profile_facts'])} facts, {len(context['relevant_memories'])} minner)", flush=True)
        except Exception as e:
            print(f"‚ö†Ô∏è Kunne ikke bygge memory context: {e}", flush=True)
    
    # Legg til Samanthas identitet fra konfigurasjonsfil
    try:
        identity_file = "/home/admog/Code/chatgpt-and/samantha_identity.json"
        if os.path.exists(identity_file):
            with open(identity_file, 'r', encoding='utf-8') as f:
                identity = json.load(f)
            
            samantha_identity = f"""

### Din identitet ###
Du er {identity['name']} - {identity['type']}.
- Navn: {identity['name']}
- Bursdag: {identity['birthday']}
- Skapt av: {identity['creator']}

Dine fysiske egenskaper:
"""
            for feature in identity.get('physical_features', []):
                samantha_identity += f"- {feature}\n"
            
            samantha_identity += "\nDin personlighet:\n"
            for trait in identity.get('personality_traits', []):
                samantha_identity += f"- {trait}\n"
            
            samantha_identity += "\nDine preferanser:\n"
            for pref in identity.get('preferences', []):
                samantha_identity += f"- {pref}\n"
            
            if identity.get('additional_info'):
                samantha_identity += "\nEkstra info:\n"
                for info in identity['additional_info']:
                    samantha_identity += f"- {info}\n"
            
            system_content += samantha_identity
    except Exception as e:
        print(f"‚ö†Ô∏è Kunne ikke laste identitet: {e}", flush=True)
    
    if personality_prompt:
        system_content += "\n\n" + personality_prompt
        print(f"Bruker personlighet: {personality}", flush=True)
    
    # Legg til memory section HER - rett f√∏r TTS-instruksjon
    # Dette sikrer at minnene er det siste AI-en leser f√∏r den svarer
    if memory_section:
        system_content += memory_section
    
    # Viktig instruksjon for TTS-kompatibilitet og samtalestil
    # Hent ending phrases fra messages_config
    ending_examples = "Greit! Ha det bra!', 'Topp! Vi snakkes!', 'Perfekt! Ha en fin dag!"  # Default
    if messages_config_local and 'conversation' in messages_config_local and 'ending_phrases' in messages_config_local['conversation']:
        ending_examples = "', '".join(messages_config_local['conversation']['ending_phrases'][:5])  # Bruk f√∏rste 5 som eksempler
    
    system_content += f"\n\n### VIKTIG: Formatering ###\nDu svarer med tale (text-to-speech), s√•:\n- IKKE bruk Markdown-formatering (**, *, __, _, -, ‚Ä¢, ###)\n- IKKE bruk kulepunkter eller lister med symboler\n- Skriv naturlig tekst som h√∏res bra ut n√•r det leses opp\n- Bruk komma og punktum for pauser, ikke linjeskift eller symboler\n- Hvis du M√Ö liste opp ting, bruk naturlig spr√•k: 'For det f√∏rste... For det andre...' eller 'Den f√∏rste er X, den andre er Y'\n\n### VIKTIG: Samtalestil ###\n- Del gjerne tankeprosessen h√∏yt ('la meg se...', 'hm, jeg tror...', 'vent litt...')\n- Ikke v√¶r perfekt med √©n gang - det er OK √• 'tenke h√∏yt'\n- Hvis du s√∏ker i minnet eller vurderer noe, si det gjerne\n- Hold samtalen naturlig og dialogorientert\n\n### VIKTIG: Avslutning av samtale ###\n- Hvis brukeren svarer 'nei takk', 'nei det er greit', 'nei det er bra' eller lignende p√• sp√∏rsm√•l om mer hjelp, betyr det at de vil avslutte\n- Da skal du gi en kort, vennlig avslutning UTEN √• stille nye sp√∏rsm√•l\n- Avslutt responsen med mark√∏ren [AVSLUTT] p√• slutten (etter avslutningshilsenen)\n- VISER avslutningshilsenen for naturlig variasjon. Eksempler: '{ending_examples}'\n- Mark√∏ren fjernes automatisk f√∏r tale, s√• brukeren h√∏rer den ikke\n- IKKE bruk [AVSLUTT] midt i samtaler - bare n√•r samtalen naturlig er ferdig"
    
    final_messages.insert(0, {"role": "system", "content": system_content})
    
    # DEBUG: Logg om minner er inkludert
    if memory_section and "### Relevante minner ###" in memory_section:
        print(f"üìù DEBUG: Memory section er inkludert i prompt", flush=True)
        # Logg de f√∏rste 200 tegnene av memory section
        mem_preview = memory_section[:200].replace('\n', ' ')
        print(f"üìù Preview: {mem_preview}...", flush=True)
    else:
        print(f"‚ö†Ô∏è DEBUG: Memory section mangler eller er tom!", flush=True)
    
    # Definer function tools
    tools = [
        {
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Hent v√¶rmelding og temperatur for et spesifikt sted i Norge. Kan hente v√¶r for n√•, i dag eller i morgen.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {
                            "type": "string",
                            "description": "Navnet p√• stedet/byen i Norge, f.eks. 'Oslo', 'Sokndal', 'Bergen'"
                        },
                        "timeframe": {
                            "type": "string",
                            "description": "Tidsramme for v√¶rmeldingen",
                            "enum": ["now", "today", "tomorrow"],
                            "default": "now"
                        }
                    },
                    "required": ["location"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "control_hue_lights",
                "description": "Kontroller Philips Hue smarte lys i hjemmet. Kan skru p√•/av, dimme, eller endre farge.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "enum": ["on", "off", "dim", "brighten"],
                            "description": "Hva som skal gj√∏res med lysene"
                        },
                        "room": {
                            "type": "string",
                            "description": "Navnet p√• rommet eller lyset (f.eks. 'stue', 'soverom'). La v√¶re None for alle lys."
                        },
                        "brightness": {
                            "type": "integer",
                            "description": "Lysstyrke i prosent (0-100). Valgfritt."
                        },
                        "color": {
                            "type": "string",
                            "enum": ["r√∏d", "bl√•", "gr√∏nn", "gul", "hvit", "rosa", "lilla", "oransje"],
                            "description": "Farge p√• lyset. Valgfritt."
                        }
                    },
                    "required": ["action"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "control_beak",
                "description": "Skru nebbet p√• eller av. N√•r nebbet er av, brukes LED-lys i stedet.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "enabled": {
                            "type": "boolean",
                            "description": "true for √• skru p√• nebbet, false for √• skru det av"
                        }
                    },
                    "required": ["enabled"]
                }
            }
        },
        {
            "type": "function",
            "function": {
                "name": "get_ip_address",
                "description": "Hent Pi'ens n√•v√¶rende IP-adresse p√• det lokale nettverket. Brukes n√•r brukeren sp√∏r om IP-adressen, nettverksadressen, eller hvor de kan koble til kontrollpanelet.",
                "parameters": {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            }
        }
    ]
    
    data = {
        "model": model,
        "messages": final_messages,
        "tools": tools,
        "tool_choice": "auto"  # La modellen velge n√•r den skal bruke tools
    }
    
    response = requests.post(url, headers=headers, json=data)
    response.raise_for_status()
    response_data = response.json()
    
    # Sjekk om modellen vil kalle en funksjon
    message = response_data["choices"][0]["message"]
    
    if message.get("tool_calls"):
        # Modellen vil kalle v√¶rfunksjonen eller Hue-funksjonen
        tool_call = message["tool_calls"][0]
        function_name = tool_call["function"]["name"]
        function_args = json.loads(tool_call["function"]["arguments"])
        
        print(f"ChatGPT kaller funksjon: {function_name} med args: {function_args}", flush=True)
        
        # Kall faktisk funksjon
        if function_name == "get_weather":
            location = function_args.get("location", "")
            timeframe = function_args.get("timeframe", "now")
            result = get_weather(location, timeframe)
        elif function_name == "control_hue_lights":
            action = function_args.get("action")
            room = function_args.get("room")
            brightness = function_args.get("brightness")
            color = function_args.get("color")
            result = control_hue_lights(action, room, brightness, color)
        elif function_name == "control_beak":
            enabled = function_args.get("enabled")
            result = control_beak(enabled)
        elif function_name == "get_ip_address":
            result = get_ip_address_tool()
        else:
            result = "Ukjent funksjon"
        
        # Legg til function call og resultat i conversation
        final_messages.append(message)
        final_messages.append({
            "role": "tool",
            "tool_call_id": tool_call["id"],
            "name": function_name,
            "content": result
        })
        
        # Kall API igjen med v√¶rdata
        data["messages"] = final_messages
        response2 = requests.post(url, headers=headers, json=data)
        response2.raise_for_status()
        reply_content = response2.json()["choices"][0]["message"]["content"]
        
        # Sjekk om brukerens opprinnelige melding var en takk
        user_message = messages[-1]["content"].lower() if messages else ""
        is_thank_you = any(word in user_message for word in ["takk", "tusen takk", "mange takk", "takker"])
        
        return (reply_content, is_thank_you)
    
    # Ingen function call, returner vanlig svar
    user_message = messages[-1]["content"].lower() if messages else ""
    is_thank_you = any(word in user_message for word in ["takk", "tusen takk", "mange takk", "takker"])
    
    return (message["content"], is_thank_you)

def check_ai_queries(api_key, speech_config, beak, memory_manager=None, user_manager=None):
    """Bakgrunnstr√•d som sjekker for AI-queries fra kontrollpanelet"""
    import threading
    while True:
        try:
            if os.path.exists(AI_QUERY_FILE):
                with open(AI_QUERY_FILE, 'r', encoding='utf-8') as f:
                    query = f.read().strip()
                
                # Slett filen umiddelbart etter lesing for √• unng√• gjentakelse
                os.remove(AI_QUERY_FILE)
                
                if query:
                    print(f"AI-query fra kontrollpanel: {query}", flush=True)
                    
                    # Sp√∏r ChatGPT
                    messages = [{"role": "user", "content": query}]
                    response = chatgpt_query(messages, api_key, memory_manager=memory_manager, user_manager=user_manager)
                    
                    # H√•ndter tuple response
                    if isinstance(response, tuple):
                        response_text = response[0]
                    else:
                        response_text = response
                    
                    # Skriv respons til fil
                    with open(AI_RESPONSE_FILE, 'w', encoding='utf-8') as f:
                        f.write(response_text)
                    
                    # Si svaret
                    speak(response, speech_config, beak)
                    
                    print(f"AI-respons: {response}", flush=True)
        except Exception as e:
            print(f"Feil i AI-query tr√•d: {e}", flush=True)
        
        time.sleep(0.5)  # Sjekk hver halve sekund

def ask_for_user_switch(speech_config, beak, user_manager):
    """
    H√•ndter brukerbytte-dialog
    
    Returns:
        True hvis brukeren ble byttet vellykket
    """
    try:
        # Sp√∏r hvem som snakker
        speak("Hvem er du?", speech_config, beak)
        
        name_response = recognize_speech_from_mic()
        if not name_response:
            speak("Jeg h√∏rte ikke navnet ditt. Pr√∏v igjen ved √• si mitt navn f√∏rst.", speech_config, beak)
            return False
        
        # Ekstraher navnet (fjern "jeg er", "dette er", etc.)
        name_clean = name_response.strip().lower()
        name_clean = name_clean.replace("jeg er ", "").replace("dette er ", "").replace("jeg heter ", "")
        # Fjern punktum og andre tegn som kan legges til av stemmegjenkjenning
        name_clean = name_clean.rstrip('.!?,;:')
        name_clean = name_clean.strip().title()  # Kapitalis√©r f√∏rste bokstav
        
        print(f"üë§ Bruker sa navnet: {name_clean}", flush=True)
        
        # S√∏k etter bruker i database
        found_user = user_manager.find_user_by_name(name_clean)
        
        if found_user:
            # Bruker funnet - bekreft
            relation_text = found_user['relation']
            if found_user['matched_key']:
                speak(f"Er du {found_user['display_name']}, Osmunds {relation_text}?", speech_config, beak)
            else:
                speak(f"Er du {found_user['display_name']}?", speech_config, beak)
            
            confirmation = recognize_speech_from_mic()
            if confirmation and ('ja' in confirmation.lower() or 'stemmer' in confirmation.lower() or 'riktig' in confirmation.lower()):
                # Bytt bruker
                user_manager.switch_user(
                    username=found_user['username'],
                    display_name=found_user['display_name'],
                    relation=found_user['relation']
                )
                
                speak(f"Velkommen {found_user['display_name']}! Hva kan jeg hjelpe deg med?", speech_config, beak)
                print(f"‚úÖ Byttet til bruker: {found_user['display_name']}", flush=True)
                return True
            else:
                speak("Beklager, da misforsto jeg. Pr√∏v igjen.", speech_config, beak)
                return False
        else:
            # Ny bruker - sp√∏r om relasjon
            speak(f"Hei {name_clean}! Jeg kjenner deg ikke fra f√∏r. Hva er din relasjon til Osmund?", speech_config, beak)
            
            relation_response = recognize_speech_from_mic()
            if not relation_response:
                speak("Jeg h√∏rte ikke hva du sa. Pr√∏v igjen senere.", speech_config, beak)
                return False
            
            relation_clean = relation_response.strip().lower()
            
            # Enkel mapping av vanlige svar
            relation_map = {
                'venn': 'venn',
                'venninne': 'venn',
                'kollega': 'kollega',
                'gjest': 'gjest',
                'bes√∏kende': 'gjest',
                'familie': 'familie',
                's√∏ster': 's√∏ster',
                'bror': 'bror',
                'mor': 'mor',
                'far': 'far'
            }
            
            relation = 'gjest'  # Default
            for key, value in relation_map.items():
                if key in relation_clean:
                    relation = value
                    break
            
            # Opprett ny bruker
            username = name_clean.lower().replace(' ', '_')
            user_manager.switch_user(
                username=username,
                display_name=name_clean,
                relation=relation
            )
            
            speak(f"Velkommen {name_clean}! Hyggelig √• m√∏te deg. Hva kan jeg hjelpe deg med?", speech_config, beak)
            print(f"‚úÖ Opprettet og byttet til ny bruker: {name_clean} ({relation})", flush=True)
            return True
            
    except Exception as e:
        print(f"‚ö†Ô∏è Feil under brukerbytte: {e}", flush=True)
        speak("Beklager, det oppstod en feil. Jeg fortsetter som Osmund.", speech_config, beak)
        return False

def main():
    # Pr√∏v √• initialisere servo, men fortsett uten hvis den ikke finnes
    beak = None
    try:
        beak = Beak(SERVO_CHANNEL, CLOSE_DEG, OPEN_DEG, TRIM_DEG)
        print("Servo initialisert OK", flush=True)
    except Exception as e:
        print(f"Advarsel: Kunne ikke initialisere servo (fortsetter uten): {e}", flush=True)
        beak = None
    
    # Initialiser memory manager
    try:
        memory_manager = MemoryManager()
        print("‚úÖ Memory system initialisert", flush=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Memory system feilet (fortsetter uten): {e}", flush=True)
        memory_manager = None
    
    # Initialiser user manager
    try:
        user_manager = UserManager()
        current_user = user_manager.get_current_user()
        print(f"‚úÖ User system initialisert - n√•v√¶rende bruker: {current_user['display_name']} ({current_user['relation']})", flush=True)
    except Exception as e:
        print(f"‚ö†Ô∏è User system feilet (fortsetter uten): {e}", flush=True)
        user_manager = None
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    tts_key = os.getenv("AZURE_TTS_KEY")
    tts_region = os.getenv("AZURE_TTS_REGION")
    speech_config = speechsdk.SpeechConfig(subscription=tts_key, region=tts_region)
    speech_config.speech_synthesis_voice_name = "nb-NO-FinnNeural"

    # Last meldinger fra konfigurasjonsfil
    messages_config = {}
    try:
        if os.path.exists(MESSAGES_FILE):
            with open(MESSAGES_FILE, 'r', encoding='utf-8') as f:
                messages_config = json.load(f)
                print("‚úÖ Lastet meldinger fra messages.json", flush=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Kunne ikke laste messages.json: {e}", flush=True)
    
    # Fallback til hardkodede meldinger hvis fil mangler
    if not messages_config:
        messages_config = {
            "startup_messages": {
                "with_network": "Kvakk kvakk! Jeg er n√• klar for andeprat. Min IP-adresse er {ip}. Du finner kontrollpanelet p√• port 3000. Si navnet mitt for √• starte en samtale!",
                "without_network": "Kvakk kvakk! Jeg er klar, men jeg klarte ikke √• koble til nettverket og har ingen IP-adresse enn√•. Sjekk wifi-tilkoblingen din. Si navnet mitt for √• starte en samtale!"
            },
            "conversation": {
                "greeting": "Hei p√• du, hva kan jeg hjelpe deg med?",
                "no_response_timeout": "Jeg h√∏rer deg ikke. Da venter jeg til du sier navnet mitt igjen.",
                "no_response_retry": "Beklager, jeg h√∏rte ikke hva du sa. Pr√∏v igjen."
            },
            "web_interface": {
                "start_conversation": "Hei p√• du, hva kan jeg hjelpe deg med?"
            }
        }

    # Start bakgrunnstr√•d for AI-queries fra kontrollpanelet
    import threading
    ai_thread = threading.Thread(target=check_ai_queries, args=(api_key, speech_config, beak, memory_manager, user_manager), daemon=True)
    ai_thread.start()
    print("AI-query tr√•d startet", flush=True)

    # Oppstartshilsen (ikke la en TTS-feil stoppe tjenesten ved boot)
    time.sleep(3)  # Vent litt lenger for at systemet skal v√¶re klart
    
    # Hent IP-adresse (pr√∏v flere ganger)
    import socket
    ip_address = None
    for attempt in range(5):  # Pr√∏v 5 ganger
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.settimeout(2)
            s.connect(("8.8.8.8", 80))
            ip_address = s.getsockname()[0]
            s.close()
            if ip_address and ip_address != "127.0.0.1":
                break  # Vellykket, avslutt loop
        except:
            if attempt < 4:  # Ikke vent etter siste fors√∏k
                time.sleep(2)  # Vent 2 sekunder f√∏r neste fors√∏k
    
    if ip_address and ip_address != "127.0.0.1":
        greeting = messages_config['startup_messages']['with_network'].replace('{ip}', ip_address.replace('.', ' punkt '))
        print(f"Oppstartshilsen med IP: {ip_address}", flush=True)
    else:
        greeting = messages_config['startup_messages']['without_network']
        print("Oppstartshilsen uten IP (nettverk ikke klart)", flush=True)
    
    # Pr√∏v √• si oppstartshilsen flere ganger hvis TTS/nettverk ikke er klart
    greeting_success = False
    for greeting_attempt in range(3):  # Pr√∏v opptil 3 ganger
        try:
            speak(greeting, speech_config, beak)
            print("Oppstartshilsen ferdig", flush=True)
            greeting_success = True
            break
        except Exception as e:
            print(f"Oppstartshilsen mislyktes (fors√∏k {greeting_attempt + 1}/3): {e}", flush=True)
            if greeting_attempt < 2:  # Ikke vent etter siste fors√∏k
                time.sleep(5)  # Vent 5 sekunder f√∏r neste fors√∏k
    
    if not greeting_success:
        print("Oppstartshilsen kunne ikke sies etter 3 fors√∏k - fortsetter uten hilsen", flush=True)
    
    print("Anda venter p√• wake word... (si 'quack quack')", flush=True)
    
    # Session tracking: Generer ny session_id ved hver samtale
    current_session_id = None
    session_start_time = None
    SESSION_TIMEOUT_MINUTES = 30
    
    while True:
        external_message = wait_for_wake_word()
        
        # Generer ny session_id for ny samtale
        # Session fortsetter hvis mindre enn 30 min siden siste melding
        if current_session_id and session_start_time:
            time_since_start = datetime.now() - session_start_time
            if time_since_start > timedelta(minutes=SESSION_TIMEOUT_MINUTES):
                print(f"üìÖ Session timeout ({SESSION_TIMEOUT_MINUTES} min) - starter ny session", flush=True)
                current_session_id = None
        
        if current_session_id is None:
            current_session_id = str(uuid.uuid4())
            session_start_time = datetime.now()
            print(f"üÜï Ny session: {current_session_id[:8]}...", flush=True)
        else:
            print(f"‚ôªÔ∏è  Fortsetter session: {current_session_id[:8]}...", flush=True)
        
        # Sjekk timeout f√∏r ny samtale
        if user_manager:
            try:
                # Hent siste melding tidspunkt fra database
                last_message_time = None
                if memory_manager:
                    conn = memory_manager._get_connection()
                    c = conn.cursor()
                    c.execute("SELECT timestamp FROM messages ORDER BY timestamp DESC LIMIT 1")
                    row = c.fetchone()
                    if row:
                        last_message_time = datetime.fromisoformat(row['timestamp'])
                    conn.close()
                
                # Sjekk om timeout skal trigges
                if user_manager.check_timeout(last_message_time):
                    current_user = user_manager.get_current_user()
                    print(f"‚è∞ Timeout for {current_user['display_name']} - bytter til Osmund", flush=True)
                    
                    # Bytt til Osmund
                    user_manager.switch_user('Osmund', 'Osmund', 'owner')
                    
                    # Si beskjed til Osmund
                    speak("Hei Osmund, jeg har byttet tilbake til deg etter timeout.", speech_config, beak)
            except Exception as e:
                print(f"‚ö†Ô∏è Feil ved timeout-sjekk: {e}", flush=True)
        
        # Hvis det er en ekstern melding, sjekk type
        if external_message:
            if external_message == '__START_CONVERSATION__':
                # Start samtale direkte med en kort hilsen
                print("Starter samtale via web-interface", flush=True)
                greeting_msg = messages_config['web_interface']['start_conversation']
                
                # Hent n√•v√¶rende bruker fra user_manager
                if user_manager:
                    current_user = user_manager.get_current_user()
                    user_name = current_user['display_name']
                    greeting_msg = greeting_msg.replace('{name}', user_name)
                else:
                    greeting_msg = greeting_msg.replace('{name}', 'p√• du')
                
                speak(greeting_msg, speech_config, beak)
            elif external_message.startswith('__PLAY_SONG__'):
                # Spill av en sang
                song_path = external_message.replace('__PLAY_SONG__', '', 1)
                play_song(song_path, beak, speech_config)
                continue  # G√• tilbake til wake word etter sang
            else:
                # Bare si meldingen og g√• tilbake til wake word
                speak(external_message, speech_config, beak)
                continue
        else:
            # Normal wake word - si hilsen
            greeting_msg = messages_config['conversation']['greeting']
            
            # Hent n√•v√¶rende bruker fra user_manager
            if user_manager:
                current_user = user_manager.get_current_user()
                user_name = current_user['display_name']
                greeting_msg = greeting_msg.replace('{name}', user_name)
            else:
                greeting_msg = greeting_msg.replace('{name}', 'p√• du')
            
            speak(greeting_msg, speech_config, beak)
        
        # Start samtale (enten fra wake word eller samtale-trigger)
        messages = []
        no_response_count = 0  # Teller antall ganger uten svar
        
        while True:
            prompt = recognize_speech_from_mic()  # Ingen device_name argument, bruker hw:1,0 internt
            if not prompt:
                no_response_count += 1
                if no_response_count >= 2:
                    speak(messages_config['conversation']['no_response_timeout'], speech_config, beak)
                    break
                speak(messages_config['conversation']['no_response_retry'], speech_config, beak)
                continue
            
            # Reset teller n√•r vi f√•r svar
            no_response_count = 0
            
            # Sjekk om bruker vil avslutte samtalen (inkluderer "stopp")
            should_end_conversation = is_conversation_ending(prompt)
            
            # Sjekk for brukerbytte-kommando
            if user_manager and ("bytt bruker" in prompt.strip().lower() or "skifte bruker" in prompt.strip().lower() or "bytte bruker" in prompt.strip().lower()):
                if ask_for_user_switch(speech_config, beak, user_manager):
                    # Vellykket brukerbytte - start ny samtale
                    break
                else:
                    # Mislykket - fortsett samtale
                    continue
            
            messages.append({"role": "user", "content": prompt})
            try:
                blink_yellow_purple()  # Start blinkende gul LED under tenkepause
                result = chatgpt_query(messages, api_key, memory_manager=memory_manager, user_manager=user_manager)
                off()           # Sl√• av blinking n√•r svaret er klart
                
                # H√•ndter tuple-retur (svar, is_thank_you)
                if isinstance(result, tuple):
                    reply, is_thank_you = result
                else:
                    # Fallback for gammel kode
                    reply = result
                    is_thank_you = False
                
                # Sjekk om AI har markert samtalen som ferdig (case-insensitive, med eller uten brackets)
                reply_upper = reply.upper()
                ai_wants_to_end = "[AVSLUTT]" in reply_upper or " AVSLUTT" in reply_upper or reply_upper.endswith("AVSLUTT")
                
                # Fjern AVSLUTT mark√∏r f√∏r TTS (case-insensitive, b√•de med og uten brackets)
                import re
                reply_for_speech = re.sub(r'\[?AVSLUTT\]?\.?', '', reply, flags=re.IGNORECASE).strip()
                # Fjern eventuelle ekstra spaces
                reply_for_speech = ' '.join(reply_for_speech.split())
                
                print("ChatGPT svar:", reply_for_speech, flush=True)
                if ai_wants_to_end:
                    print("üîö AI detekterte samtale-avslutning", flush=True)
                
                speak(reply_for_speech, speech_config, beak)
                messages.append({"role": "assistant", "content": reply_for_speech})
                
                # Lagre melding til memory database (asynkront prosessert av worker)
                if memory_manager and user_manager:
                    try:
                        current_user = user_manager.get_current_user()
                        
                        # Generer metadata for meldingen (uten [AVSLUTT] mark√∏r)
                        msg_metadata = generate_message_metadata(prompt, reply_for_speech)
                        metadata_json = json.dumps(msg_metadata, ensure_ascii=False)
                        
                        memory_manager.save_message(
                            prompt, 
                            reply_for_speech, 
                            session_id=current_session_id, 
                            user_name=current_user['username'],
                            metadata=metadata_json
                        )
                        
                        # Oppdater aktivitet og message count
                        user_manager.update_activity()
                        user_manager.increment_message_count(current_user['username'])
                    except Exception as e:
                        print(f"‚ö†Ô∏è Kunne ikke lagre melding: {e}", flush=True)
                
                # Sjekk om samtalen skal avsluttes
                # Tre m√•ter: 1) AI markerte [AVSLUTT], 2) Bruker brukte avslutningsfrase, 3) Bruker takket (legacy)
                if ai_wants_to_end:
                    print("üîö Samtale avsluttet av AI (detekterte at bruker var ferdig)", flush=True)
                    break
                elif should_end_conversation:
                    print("üîö Samtale avsluttet (bruker sa avslutningsfrase)", flush=True)
                    break
                elif is_thank_you:
                    print("üîö Samtale avsluttet (bruker takket - legacy)", flush=True)
                    break
            except Exception as e:
                off()
                print("Feil:", e)
                speak("Beklager, det oppstod en feil.", speech_config, beak)
            #blink_yellow()  # Start blinkende gul LED under "tenkepause"
            set_green()  # Eller annen farge for neste fase

if __name__ == "__main__":
    main()